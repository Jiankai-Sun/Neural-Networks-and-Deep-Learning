{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9130 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9287 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9296 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9357 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9363 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9380 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9393 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9416 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9394 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9441 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9432 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9459 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9455 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9464 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9481 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9450 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9470 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9418 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9496 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9474 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9492 / 10000\n"
     ]
    }
   ],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10], cost = network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5, evaluation_data = test_data, monitor_evaluation_accuracy = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 2.037294073618446\n",
      "Accuracy on evaluation data: 5343 / 10000\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 1.466598860127497\n",
      "Accuracy on evaluation data: 6541 / 10000\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 1.209483422175193\n",
      "Accuracy on evaluation data: 7040 / 10000\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 1.0386860426367834\n",
      "Accuracy on evaluation data: 7139 / 10000\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 0.8828615328238321\n",
      "Accuracy on evaluation data: 7403 / 10000\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 0.7790977180297085\n",
      "Accuracy on evaluation data: 7493 / 10000\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 0.6935696078439619\n",
      "Accuracy on evaluation data: 7667 / 10000\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 0.5937176537786819\n",
      "Accuracy on evaluation data: 7752 / 10000\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 0.5558437325390387\n",
      "Accuracy on evaluation data: 7691 / 10000\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 0.4936969781678606\n",
      "Accuracy on evaluation data: 7835 / 10000\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 0.44093412494643974\n",
      "Accuracy on evaluation data: 7857 / 10000\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 0.41097588502455035\n",
      "Accuracy on evaluation data: 7901 / 10000\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 0.36099438790661753\n",
      "Accuracy on evaluation data: 7899 / 10000\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 0.3355971259421899\n",
      "Accuracy on evaluation data: 7939 / 10000\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 0.32218311655730636\n",
      "Accuracy on evaluation data: 7930 / 10000\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 0.287654779216103\n",
      "Accuracy on evaluation data: 7982 / 10000\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 0.26679971397381624\n",
      "Accuracy on evaluation data: 7999 / 10000\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 0.25065770990281633\n",
      "Accuracy on evaluation data: 7981 / 10000\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 0.22970728759290684\n",
      "Accuracy on evaluation data: 7972 / 10000\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 0.2210713967367204\n",
      "Accuracy on evaluation data: 7984 / 10000\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 0.20535108077423825\n",
      "Accuracy on evaluation data: 7997 / 10000\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 0.19335939020634235\n",
      "Accuracy on evaluation data: 7989 / 10000\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 0.18126270572980432\n",
      "Accuracy on evaluation data: 8019 / 10000\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 0.17439471460788653\n",
      "Accuracy on evaluation data: 7986 / 10000\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 0.16256449668317613\n",
      "Accuracy on evaluation data: 8043 / 10000\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 0.15748352884280237\n",
      "Accuracy on evaluation data: 8001 / 10000\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 0.14612694009913618\n",
      "Accuracy on evaluation data: 8024 / 10000\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 0.13935406401829797\n",
      "Accuracy on evaluation data: 8047 / 10000\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 0.13306113281194376\n",
      "Accuracy on evaluation data: 8013 / 10000\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 0.12750815774784222\n",
      "Accuracy on evaluation data: 8007 / 10000\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 0.12187446376267563\n",
      "Accuracy on evaluation data: 8014 / 10000\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 0.11616684688154032\n",
      "Accuracy on evaluation data: 8019 / 10000\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 0.11242925917101829\n",
      "Accuracy on evaluation data: 8030 / 10000\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 0.10846760323678388\n",
      "Accuracy on evaluation data: 8016 / 10000\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 0.1040086027662091\n",
      "Accuracy on evaluation data: 8021 / 10000\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 0.09967976699605255\n",
      "Accuracy on evaluation data: 8037 / 10000\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 0.0968167807246271\n",
      "Accuracy on evaluation data: 8048 / 10000\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 0.09310863203277639\n",
      "Accuracy on evaluation data: 8035 / 10000\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 0.0896672289281927\n",
      "Accuracy on evaluation data: 8047 / 10000\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 0.08734139531117582\n",
      "Accuracy on evaluation data: 8034 / 10000\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 0.08421012081264546\n",
      "Accuracy on evaluation data: 8014 / 10000\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 0.08094092798375707\n",
      "Accuracy on evaluation data: 8022 / 10000\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 0.08076973066947853\n",
      "Accuracy on evaluation data: 8011 / 10000\n",
      "Epoch 43 training complete\n",
      "Cost on training data: 0.07648607831993239\n",
      "Accuracy on evaluation data: 8035 / 10000\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 0.07538978424260519\n",
      "Accuracy on evaluation data: 8052 / 10000\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 0.0716150302152069\n",
      "Accuracy on evaluation data: 8056 / 10000\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 0.06979560406921825\n",
      "Accuracy on evaluation data: 8053 / 10000\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 0.06751208558665635\n",
      "Accuracy on evaluation data: 8018 / 10000\n",
      "Epoch 48 training complete\n",
      "Cost on training data: 0.06495902575957943\n",
      "Accuracy on evaluation data: 8023 / 10000\n",
      "Epoch 49 training complete\n",
      "Cost on training data: 0.0627049020321298\n",
      "Accuracy on evaluation data: 8057 / 10000\n",
      "Epoch 50 training complete\n",
      "Cost on training data: 0.06122639691991428\n",
      "Accuracy on evaluation data: 8041 / 10000\n",
      "Epoch 51 training complete\n",
      "Cost on training data: 0.059577451796716765\n",
      "Accuracy on evaluation data: 8063 / 10000\n",
      "Epoch 52 training complete\n",
      "Cost on training data: 0.05783353973001736\n",
      "Accuracy on evaluation data: 8056 / 10000\n",
      "Epoch 53 training complete\n",
      "Cost on training data: 0.05622265859601268\n",
      "Accuracy on evaluation data: 8057 / 10000\n",
      "Epoch 54 training complete\n",
      "Cost on training data: 0.054880996620226975\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 55 training complete\n",
      "Cost on training data: 0.053843708848171634\n",
      "Accuracy on evaluation data: 8039 / 10000\n",
      "Epoch 56 training complete\n",
      "Cost on training data: 0.05263221105156923\n",
      "Accuracy on evaluation data: 8064 / 10000\n",
      "Epoch 57 training complete\n",
      "Cost on training data: 0.05098869960846912\n",
      "Accuracy on evaluation data: 8055 / 10000\n",
      "Epoch 58 training complete\n",
      "Cost on training data: 0.050044543763605474\n",
      "Accuracy on evaluation data: 8047 / 10000\n",
      "Epoch 59 training complete\n",
      "Cost on training data: 0.04877903044052708\n",
      "Accuracy on evaluation data: 8077 / 10000\n",
      "Epoch 60 training complete\n",
      "Cost on training data: 0.04817300014915123\n",
      "Accuracy on evaluation data: 8049 / 10000\n",
      "Epoch 61 training complete\n",
      "Cost on training data: 0.046575495637144956\n",
      "Accuracy on evaluation data: 8055 / 10000\n",
      "Epoch 62 training complete\n",
      "Cost on training data: 0.04549241864797911\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 63 training complete\n",
      "Cost on training data: 0.04436344667193841\n",
      "Accuracy on evaluation data: 8059 / 10000\n",
      "Epoch 64 training complete\n",
      "Cost on training data: 0.04346915550337046\n",
      "Accuracy on evaluation data: 8072 / 10000\n",
      "Epoch 65 training complete\n",
      "Cost on training data: 0.042531601052889875\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 66 training complete\n",
      "Cost on training data: 0.04149279176411189\n",
      "Accuracy on evaluation data: 8060 / 10000\n",
      "Epoch 67 training complete\n",
      "Cost on training data: 0.04069458372651247\n",
      "Accuracy on evaluation data: 8060 / 10000\n",
      "Epoch 68 training complete\n",
      "Cost on training data: 0.03991689290647326\n",
      "Accuracy on evaluation data: 8045 / 10000\n",
      "Epoch 69 training complete\n",
      "Cost on training data: 0.03903107415114984\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 70 training complete\n",
      "Cost on training data: 0.03823103406012879\n",
      "Accuracy on evaluation data: 8055 / 10000\n",
      "Epoch 71 training complete\n",
      "Cost on training data: 0.03751496729760626\n",
      "Accuracy on evaluation data: 8063 / 10000\n",
      "Epoch 72 training complete\n",
      "Cost on training data: 0.036832974997745765\n",
      "Accuracy on evaluation data: 8063 / 10000\n",
      "Epoch 73 training complete\n",
      "Cost on training data: 0.036313347107492656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on evaluation data: 8079 / 10000\n",
      "Epoch 74 training complete\n",
      "Cost on training data: 0.035538566283575976\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 75 training complete\n",
      "Cost on training data: 0.034862797587626004\n",
      "Accuracy on evaluation data: 8058 / 10000\n",
      "Epoch 76 training complete\n",
      "Cost on training data: 0.034137080990976204\n",
      "Accuracy on evaluation data: 8058 / 10000\n",
      "Epoch 77 training complete\n",
      "Cost on training data: 0.033525132770197974\n",
      "Accuracy on evaluation data: 8067 / 10000\n",
      "Epoch 78 training complete\n",
      "Cost on training data: 0.033031238014724795\n",
      "Accuracy on evaluation data: 8060 / 10000\n",
      "Epoch 79 training complete\n",
      "Cost on training data: 0.03236815090310932\n",
      "Accuracy on evaluation data: 8054 / 10000\n",
      "Epoch 80 training complete\n",
      "Cost on training data: 0.031767258470523224\n",
      "Accuracy on evaluation data: 8060 / 10000\n",
      "Epoch 81 training complete\n",
      "Cost on training data: 0.03114484877357657\n",
      "Accuracy on evaluation data: 8060 / 10000\n",
      "Epoch 82 training complete\n",
      "Cost on training data: 0.03059858846188776\n",
      "Accuracy on evaluation data: 8062 / 10000\n",
      "Epoch 83 training complete\n",
      "Cost on training data: 0.03005221734769702\n",
      "Accuracy on evaluation data: 8055 / 10000\n",
      "Epoch 84 training complete\n",
      "Cost on training data: 0.029540164139028907\n",
      "Accuracy on evaluation data: 8071 / 10000\n",
      "Epoch 85 training complete\n",
      "Cost on training data: 0.02920226031343202\n",
      "Accuracy on evaluation data: 8046 / 10000\n",
      "Epoch 86 training complete\n",
      "Cost on training data: 0.02855428788384358\n",
      "Accuracy on evaluation data: 8070 / 10000\n",
      "Epoch 87 training complete\n",
      "Cost on training data: 0.02810710070016078\n",
      "Accuracy on evaluation data: 8050 / 10000\n",
      "Epoch 88 training complete\n",
      "Cost on training data: 0.02760547356988182\n",
      "Accuracy on evaluation data: 8053 / 10000\n",
      "Epoch 89 training complete\n",
      "Cost on training data: 0.027124154432859475\n",
      "Accuracy on evaluation data: 8053 / 10000\n",
      "Epoch 90 training complete\n",
      "Cost on training data: 0.02661087956461544\n",
      "Accuracy on evaluation data: 8066 / 10000\n",
      "Epoch 91 training complete\n",
      "Cost on training data: 0.0261518741407643\n",
      "Accuracy on evaluation data: 8061 / 10000\n",
      "Epoch 92 training complete\n",
      "Cost on training data: 0.025705930091880325\n",
      "Accuracy on evaluation data: 8058 / 10000\n",
      "Epoch 93 training complete\n",
      "Cost on training data: 0.025304423458804758\n",
      "Accuracy on evaluation data: 8063 / 10000\n",
      "Epoch 94 training complete\n",
      "Cost on training data: 0.024851046127933592\n",
      "Accuracy on evaluation data: 8054 / 10000\n",
      "Epoch 95 training complete\n",
      "Cost on training data: 0.024400789698142567\n",
      "Accuracy on evaluation data: 8059 / 10000\n",
      "Epoch 96 training complete\n",
      "Cost on training data: 0.0240458779371107\n",
      "Accuracy on evaluation data: 8050 / 10000\n",
      "Epoch 97 training complete\n",
      "Cost on training data: 0.023636551500097146\n",
      "Accuracy on evaluation data: 8068 / 10000\n",
      "Epoch 98 training complete\n",
      "Cost on training data: 0.02321164104731049\n",
      "Accuracy on evaluation data: 8062 / 10000\n",
      "Epoch 99 training complete\n",
      "Cost on training data: 0.02287474981263177\n",
      "Accuracy on evaluation data: 8064 / 10000\n",
      "Epoch 100 training complete\n",
      "Cost on training data: 0.022552708371968315\n",
      "Accuracy on evaluation data: 8082 / 10000\n",
      "Epoch 101 training complete\n",
      "Cost on training data: 0.022205054754696165\n",
      "Accuracy on evaluation data: 8066 / 10000\n",
      "Epoch 102 training complete\n",
      "Cost on training data: 0.02187226649114053\n",
      "Accuracy on evaluation data: 8063 / 10000\n",
      "Epoch 103 training complete\n",
      "Cost on training data: 0.02154176285894043\n",
      "Accuracy on evaluation data: 8074 / 10000\n",
      "Epoch 104 training complete\n",
      "Cost on training data: 0.02123240214114371\n",
      "Accuracy on evaluation data: 8070 / 10000\n",
      "Epoch 105 training complete\n",
      "Cost on training data: 0.02094585033567101\n",
      "Accuracy on evaluation data: 8071 / 10000\n",
      "Epoch 106 training complete\n",
      "Cost on training data: 0.020668272365088655\n",
      "Accuracy on evaluation data: 8074 / 10000\n",
      "Epoch 107 training complete\n",
      "Cost on training data: 0.020397955049272755\n",
      "Accuracy on evaluation data: 8072 / 10000\n",
      "Epoch 108 training complete\n",
      "Cost on training data: 0.020131060828968116\n",
      "Accuracy on evaluation data: 8073 / 10000\n",
      "Epoch 109 training complete\n",
      "Cost on training data: 0.019873591373278956\n",
      "Accuracy on evaluation data: 8076 / 10000\n",
      "Epoch 110 training complete\n",
      "Cost on training data: 0.0196304149224637\n",
      "Accuracy on evaluation data: 8076 / 10000\n",
      "Epoch 111 training complete\n",
      "Cost on training data: 0.01939991256914769\n",
      "Accuracy on evaluation data: 8078 / 10000\n",
      "Epoch 112 training complete\n",
      "Cost on training data: 0.019151976796030184\n",
      "Accuracy on evaluation data: 8071 / 10000\n",
      "Epoch 113 training complete\n",
      "Cost on training data: 0.018940656523688884\n",
      "Accuracy on evaluation data: 8080 / 10000\n",
      "Epoch 114 training complete\n",
      "Cost on training data: 0.018703531575515606\n",
      "Accuracy on evaluation data: 8081 / 10000\n",
      "Epoch 115 training complete\n",
      "Cost on training data: 0.018491898604476573\n",
      "Accuracy on evaluation data: 8077 / 10000\n",
      "Epoch 116 training complete\n",
      "Cost on training data: 0.018286754974806474\n",
      "Accuracy on evaluation data: 8075 / 10000\n",
      "Epoch 117 training complete\n",
      "Cost on training data: 0.0180720064927346\n",
      "Accuracy on evaluation data: 8076 / 10000\n",
      "Epoch 118 training complete\n",
      "Cost on training data: 0.0178684464427541\n",
      "Accuracy on evaluation data: 8083 / 10000\n",
      "Epoch 119 training complete\n",
      "Cost on training data: 0.017671404457560446\n",
      "Accuracy on evaluation data: 8077 / 10000\n",
      "Epoch 120 training complete\n",
      "Cost on training data: 0.017474745022920634\n",
      "Accuracy on evaluation data: 8082 / 10000\n",
      "Epoch 121 training complete\n",
      "Cost on training data: 0.017288760293943047\n",
      "Accuracy on evaluation data: 8079 / 10000\n",
      "Epoch 122 training complete\n",
      "Cost on training data: 0.017105952272357408\n",
      "Accuracy on evaluation data: 8074 / 10000\n",
      "Epoch 123 training complete\n",
      "Cost on training data: 0.01693365123943654\n",
      "Accuracy on evaluation data: 8078 / 10000\n",
      "Epoch 124 training complete\n",
      "Cost on training data: 0.016746541657554476\n",
      "Accuracy on evaluation data: 8085 / 10000\n",
      "Epoch 125 training complete\n",
      "Cost on training data: 0.016581670343325475\n",
      "Accuracy on evaluation data: 8078 / 10000\n",
      "Epoch 126 training complete\n",
      "Cost on training data: 0.01640747349453707\n",
      "Accuracy on evaluation data: 8074 / 10000\n",
      "Epoch 127 training complete\n",
      "Cost on training data: 0.01624126074233652\n",
      "Accuracy on evaluation data: 8086 / 10000\n",
      "Epoch 128 training complete\n",
      "Cost on training data: 0.016084514413599288\n",
      "Accuracy on evaluation data: 8084 / 10000\n",
      "Epoch 129 training complete\n",
      "Cost on training data: 0.015912789025852428\n",
      "Accuracy on evaluation data: 8082 / 10000\n",
      "Epoch 130 training complete\n",
      "Cost on training data: 0.015754518947854526\n",
      "Accuracy on evaluation data: 8079 / 10000\n",
      "Epoch 131 training complete\n",
      "Cost on training data: 0.015607334841301434\n",
      "Accuracy on evaluation data: 8081 / 10000\n",
      "Epoch 132 training complete\n",
      "Cost on training data: 0.015452438193206193\n",
      "Accuracy on evaluation data: 8089 / 10000\n",
      "Epoch 133 training complete\n",
      "Cost on training data: 0.015305876740787941\n",
      "Accuracy on evaluation data: 8085 / 10000\n",
      "Epoch 134 training complete\n",
      "Cost on training data: 0.015164763148056386\n",
      "Accuracy on evaluation data: 8079 / 10000\n",
      "Epoch 135 training complete\n",
      "Cost on training data: 0.015016129443531265\n",
      "Accuracy on evaluation data: 8086 / 10000\n",
      "Epoch 136 training complete\n",
      "Cost on training data: 0.014874245974003913\n",
      "Accuracy on evaluation data: 8086 / 10000\n",
      "Epoch 137 training complete\n",
      "Cost on training data: 0.014733868434479448\n",
      "Accuracy on evaluation data: 8088 / 10000\n",
      "Epoch 138 training complete\n",
      "Cost on training data: 0.01459398047982812\n",
      "Accuracy on evaluation data: 8093 / 10000\n",
      "Epoch 139 training complete\n",
      "Cost on training data: 0.014465228195940243\n",
      "Accuracy on evaluation data: 8091 / 10000\n",
      "Epoch 140 training complete\n",
      "Cost on training data: 0.014336569435624093\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 141 training complete\n",
      "Cost on training data: 0.014192132224060601\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 142 training complete\n",
      "Cost on training data: 0.014065785130490357\n",
      "Accuracy on evaluation data: 8091 / 10000\n",
      "Epoch 143 training complete\n",
      "Cost on training data: 0.013936745792577617\n",
      "Accuracy on evaluation data: 8097 / 10000\n",
      "Epoch 144 training complete\n",
      "Cost on training data: 0.013815733713413431\n",
      "Accuracy on evaluation data: 8092 / 10000\n",
      "Epoch 145 training complete\n",
      "Cost on training data: 0.013686658027460843\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 146 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 0.013563067561822854\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 147 training complete\n",
      "Cost on training data: 0.013441785197345372\n",
      "Accuracy on evaluation data: 8089 / 10000\n",
      "Epoch 148 training complete\n",
      "Cost on training data: 0.013326910717478978\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 149 training complete\n",
      "Cost on training data: 0.013203526333499216\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 150 training complete\n",
      "Cost on training data: 0.013085236139448174\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 151 training complete\n",
      "Cost on training data: 0.012967735863243747\n",
      "Accuracy on evaluation data: 8093 / 10000\n",
      "Epoch 152 training complete\n",
      "Cost on training data: 0.01285333457877356\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 153 training complete\n",
      "Cost on training data: 0.012741963555535335\n",
      "Accuracy on evaluation data: 8092 / 10000\n",
      "Epoch 154 training complete\n",
      "Cost on training data: 0.012632994146132042\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 155 training complete\n",
      "Cost on training data: 0.012517953410473213\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 156 training complete\n",
      "Cost on training data: 0.012413457900446748\n",
      "Accuracy on evaluation data: 8095 / 10000\n",
      "Epoch 157 training complete\n",
      "Cost on training data: 0.012300859471193495\n",
      "Accuracy on evaluation data: 8098 / 10000\n",
      "Epoch 158 training complete\n",
      "Cost on training data: 0.012197779490593636\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 159 training complete\n",
      "Cost on training data: 0.012096335713110334\n",
      "Accuracy on evaluation data: 8098 / 10000\n",
      "Epoch 160 training complete\n",
      "Cost on training data: 0.011991413722200398\n",
      "Accuracy on evaluation data: 8093 / 10000\n",
      "Epoch 161 training complete\n",
      "Cost on training data: 0.011888241819214449\n",
      "Accuracy on evaluation data: 8093 / 10000\n",
      "Epoch 162 training complete\n",
      "Cost on training data: 0.011790158542976523\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 163 training complete\n",
      "Cost on training data: 0.01169661741974759\n",
      "Accuracy on evaluation data: 8097 / 10000\n",
      "Epoch 164 training complete\n",
      "Cost on training data: 0.0115956408046912\n",
      "Accuracy on evaluation data: 8099 / 10000\n",
      "Epoch 165 training complete\n",
      "Cost on training data: 0.011498777442270094\n",
      "Accuracy on evaluation data: 8098 / 10000\n",
      "Epoch 166 training complete\n",
      "Cost on training data: 0.011408074538770662\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 167 training complete\n",
      "Cost on training data: 0.01131317744619116\n",
      "Accuracy on evaluation data: 8101 / 10000\n",
      "Epoch 168 training complete\n",
      "Cost on training data: 0.011220552282563552\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 169 training complete\n",
      "Cost on training data: 0.011134036464036743\n",
      "Accuracy on evaluation data: 8095 / 10000\n",
      "Epoch 170 training complete\n",
      "Cost on training data: 0.011044699651372685\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 171 training complete\n",
      "Cost on training data: 0.010962641897427504\n",
      "Accuracy on evaluation data: 8089 / 10000\n",
      "Epoch 172 training complete\n",
      "Cost on training data: 0.010871056305820153\n",
      "Accuracy on evaluation data: 8093 / 10000\n",
      "Epoch 173 training complete\n",
      "Cost on training data: 0.010787620259445971\n",
      "Accuracy on evaluation data: 8094 / 10000\n",
      "Epoch 174 training complete\n",
      "Cost on training data: 0.010707881323061684\n",
      "Accuracy on evaluation data: 8095 / 10000\n",
      "Epoch 175 training complete\n",
      "Cost on training data: 0.010627482587982778\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 176 training complete\n",
      "Cost on training data: 0.010546156160922072\n",
      "Accuracy on evaluation data: 8099 / 10000\n",
      "Epoch 177 training complete\n",
      "Cost on training data: 0.010466851041727926\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 178 training complete\n",
      "Cost on training data: 0.010388518886649455\n",
      "Accuracy on evaluation data: 8096 / 10000\n",
      "Epoch 179 training complete\n",
      "Cost on training data: 0.010315034734019797\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 180 training complete\n",
      "Cost on training data: 0.010236728286837535\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 181 training complete\n",
      "Cost on training data: 0.010162386349029155\n",
      "Accuracy on evaluation data: 8098 / 10000\n",
      "Epoch 182 training complete\n",
      "Cost on training data: 0.010089111881778325\n",
      "Accuracy on evaluation data: 8099 / 10000\n",
      "Epoch 183 training complete\n",
      "Cost on training data: 0.010018200765469023\n",
      "Accuracy on evaluation data: 8104 / 10000\n",
      "Epoch 184 training complete\n",
      "Cost on training data: 0.009949395909760394\n",
      "Accuracy on evaluation data: 8099 / 10000\n",
      "Epoch 185 training complete\n",
      "Cost on training data: 0.009877098607800672\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 186 training complete\n",
      "Cost on training data: 0.009807516355663667\n",
      "Accuracy on evaluation data: 8101 / 10000\n",
      "Epoch 187 training complete\n",
      "Cost on training data: 0.009742354524665988\n",
      "Accuracy on evaluation data: 8098 / 10000\n",
      "Epoch 188 training complete\n",
      "Cost on training data: 0.009673432051591177\n",
      "Accuracy on evaluation data: 8101 / 10000\n",
      "Epoch 189 training complete\n",
      "Cost on training data: 0.009609146260113095\n",
      "Accuracy on evaluation data: 8102 / 10000\n",
      "Epoch 190 training complete\n",
      "Cost on training data: 0.009542454805838922\n",
      "Accuracy on evaluation data: 8103 / 10000\n",
      "Epoch 191 training complete\n",
      "Cost on training data: 0.009477059578610836\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 192 training complete\n",
      "Cost on training data: 0.009413175522692468\n",
      "Accuracy on evaluation data: 8104 / 10000\n",
      "Epoch 193 training complete\n",
      "Cost on training data: 0.0093519393293542\n",
      "Accuracy on evaluation data: 8102 / 10000\n",
      "Epoch 194 training complete\n",
      "Cost on training data: 0.009289387290463\n",
      "Accuracy on evaluation data: 8103 / 10000\n",
      "Epoch 195 training complete\n",
      "Cost on training data: 0.009229130424405279\n",
      "Accuracy on evaluation data: 8101 / 10000\n",
      "Epoch 196 training complete\n",
      "Cost on training data: 0.00916880141482676\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 197 training complete\n",
      "Cost on training data: 0.009108703040430348\n",
      "Accuracy on evaluation data: 8103 / 10000\n",
      "Epoch 198 training complete\n",
      "Cost on training data: 0.009051642398788516\n",
      "Accuracy on evaluation data: 8102 / 10000\n",
      "Epoch 199 training complete\n",
      "Cost on training data: 0.00899196279073161\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 200 training complete\n",
      "Cost on training data: 0.008934908777081557\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 201 training complete\n",
      "Cost on training data: 0.008881211969627698\n",
      "Accuracy on evaluation data: 8104 / 10000\n",
      "Epoch 202 training complete\n",
      "Cost on training data: 0.008828053458083919\n",
      "Accuracy on evaluation data: 8103 / 10000\n",
      "Epoch 203 training complete\n",
      "Cost on training data: 0.008769666925760741\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 204 training complete\n",
      "Cost on training data: 0.008715873881471065\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 205 training complete\n",
      "Cost on training data: 0.00866121326626172\n",
      "Accuracy on evaluation data: 8108 / 10000\n",
      "Epoch 206 training complete\n",
      "Cost on training data: 0.00860776891591397\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 207 training complete\n",
      "Cost on training data: 0.008555755034483482\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 208 training complete\n",
      "Cost on training data: 0.008503346679783523\n",
      "Accuracy on evaluation data: 8104 / 10000\n",
      "Epoch 209 training complete\n",
      "Cost on training data: 0.008452698250760022\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 210 training complete\n",
      "Cost on training data: 0.008401773071975323\n",
      "Accuracy on evaluation data: 8108 / 10000\n",
      "Epoch 211 training complete\n",
      "Cost on training data: 0.008352657144935636\n",
      "Accuracy on evaluation data: 8109 / 10000\n",
      "Epoch 212 training complete\n",
      "Cost on training data: 0.008304029017222204\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 213 training complete\n",
      "Cost on training data: 0.008254691696246258\n",
      "Accuracy on evaluation data: 8106 / 10000\n",
      "Epoch 214 training complete\n",
      "Cost on training data: 0.008205490466563466\n",
      "Accuracy on evaluation data: 8105 / 10000\n",
      "Epoch 215 training complete\n",
      "Cost on training data: 0.008158151335205517\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 216 training complete\n",
      "Cost on training data: 0.008110671490829845\n",
      "Accuracy on evaluation data: 8109 / 10000\n",
      "Epoch 217 training complete\n",
      "Cost on training data: 0.008065284915451342\n",
      "Accuracy on evaluation data: 8105 / 10000\n",
      "Epoch 218 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 0.008018863605653114\n",
      "Accuracy on evaluation data: 8105 / 10000\n",
      "Epoch 219 training complete\n",
      "Cost on training data: 0.007973013984025766\n",
      "Accuracy on evaluation data: 8105 / 10000\n",
      "Epoch 220 training complete\n",
      "Cost on training data: 0.007928632511646378\n",
      "Accuracy on evaluation data: 8107 / 10000\n",
      "Epoch 221 training complete\n",
      "Cost on training data: 0.007884142133450433\n",
      "Accuracy on evaluation data: 8109 / 10000\n",
      "Epoch 222 training complete\n",
      "Cost on training data: 0.007839401766992686\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 223 training complete\n",
      "Cost on training data: 0.0077955019918271385\n",
      "Accuracy on evaluation data: 8112 / 10000\n",
      "Epoch 224 training complete\n",
      "Cost on training data: 0.0077522806957565915\n",
      "Accuracy on evaluation data: 8109 / 10000\n",
      "Epoch 225 training complete\n",
      "Cost on training data: 0.0077099903112721095\n",
      "Accuracy on evaluation data: 8111 / 10000\n",
      "Epoch 226 training complete\n",
      "Cost on training data: 0.007667607484818351\n",
      "Accuracy on evaluation data: 8112 / 10000\n",
      "Epoch 227 training complete\n",
      "Cost on training data: 0.0076262765139854215\n",
      "Accuracy on evaluation data: 8111 / 10000\n",
      "Epoch 228 training complete\n",
      "Cost on training data: 0.007584770535752194\n",
      "Accuracy on evaluation data: 8113 / 10000\n",
      "Epoch 229 training complete\n",
      "Cost on training data: 0.007543480276118179\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 230 training complete\n",
      "Cost on training data: 0.00750249256612285\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 231 training complete\n",
      "Cost on training data: 0.0074631153666743786\n",
      "Accuracy on evaluation data: 8112 / 10000\n",
      "Epoch 232 training complete\n",
      "Cost on training data: 0.007423017899695742\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 233 training complete\n",
      "Cost on training data: 0.00738401802515578\n",
      "Accuracy on evaluation data: 8110 / 10000\n",
      "Epoch 234 training complete\n",
      "Cost on training data: 0.007344812592579571\n",
      "Accuracy on evaluation data: 8112 / 10000\n",
      "Epoch 235 training complete\n",
      "Cost on training data: 0.007306467508814977\n",
      "Accuracy on evaluation data: 8112 / 10000\n",
      "Epoch 236 training complete\n",
      "Cost on training data: 0.0072681156664966265\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 237 training complete\n",
      "Cost on training data: 0.007230609740296254\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 238 training complete\n",
      "Cost on training data: 0.007192958952614471\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 239 training complete\n",
      "Cost on training data: 0.007156061221820221\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 240 training complete\n",
      "Cost on training data: 0.007119603830089024\n",
      "Accuracy on evaluation data: 8113 / 10000\n",
      "Epoch 241 training complete\n",
      "Cost on training data: 0.007083135229152997\n",
      "Accuracy on evaluation data: 8114 / 10000\n",
      "Epoch 242 training complete\n",
      "Cost on training data: 0.007046882469310156\n",
      "Accuracy on evaluation data: 8113 / 10000\n",
      "Epoch 243 training complete\n",
      "Cost on training data: 0.007011304675296335\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 244 training complete\n",
      "Cost on training data: 0.006976461245462313\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 245 training complete\n",
      "Cost on training data: 0.006941236001725281\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 246 training complete\n",
      "Cost on training data: 0.006907224648517746\n",
      "Accuracy on evaluation data: 8114 / 10000\n",
      "Epoch 247 training complete\n",
      "Cost on training data: 0.006872383129557955\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 248 training complete\n",
      "Cost on training data: 0.00683820622344104\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 249 training complete\n",
      "Cost on training data: 0.006804871914827978\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 250 training complete\n",
      "Cost on training data: 0.006771492190059223\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 251 training complete\n",
      "Cost on training data: 0.0067381696988025735\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 252 training complete\n",
      "Cost on training data: 0.006705104449045231\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 253 training complete\n",
      "Cost on training data: 0.006673199390666187\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 254 training complete\n",
      "Cost on training data: 0.006640209897469898\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 255 training complete\n",
      "Cost on training data: 0.006608477213238903\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 256 training complete\n",
      "Cost on training data: 0.006576810146023579\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 257 training complete\n",
      "Cost on training data: 0.006545608303944965\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 258 training complete\n",
      "Cost on training data: 0.006514754907852144\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 259 training complete\n",
      "Cost on training data: 0.00648346856684067\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 260 training complete\n",
      "Cost on training data: 0.006453053806082772\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 261 training complete\n",
      "Cost on training data: 0.00642290317456923\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "Epoch 262 training complete\n",
      "Cost on training data: 0.006392680839484403\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 263 training complete\n",
      "Cost on training data: 0.006362902062216493\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 264 training complete\n",
      "Cost on training data: 0.006333235900405374\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 265 training complete\n",
      "Cost on training data: 0.006304161862824516\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 266 training complete\n",
      "Cost on training data: 0.0062751868585244255\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 267 training complete\n",
      "Cost on training data: 0.006246884453225946\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 268 training complete\n",
      "Cost on training data: 0.006217588410831163\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "Epoch 269 training complete\n",
      "Cost on training data: 0.006189064483143848\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 270 training complete\n",
      "Cost on training data: 0.00616103321183414\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 271 training complete\n",
      "Cost on training data: 0.006133384777698307\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 272 training complete\n",
      "Cost on training data: 0.006105444347070122\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 273 training complete\n",
      "Cost on training data: 0.006078263655408658\n",
      "Accuracy on evaluation data: 8115 / 10000\n",
      "Epoch 274 training complete\n",
      "Cost on training data: 0.00605091059397615\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 275 training complete\n",
      "Cost on training data: 0.006024586087538138\n",
      "Accuracy on evaluation data: 8114 / 10000\n",
      "Epoch 276 training complete\n",
      "Cost on training data: 0.005997236706941566\n",
      "Accuracy on evaluation data: 8116 / 10000\n",
      "Epoch 277 training complete\n",
      "Cost on training data: 0.005970901687285979\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 278 training complete\n",
      "Cost on training data: 0.005944421447206545\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 279 training complete\n",
      "Cost on training data: 0.0059184421964943446\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 280 training complete\n",
      "Cost on training data: 0.005892221723246493\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 281 training complete\n",
      "Cost on training data: 0.005866799342552188\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 282 training complete\n",
      "Cost on training data: 0.0058414799339999626\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 283 training complete\n",
      "Cost on training data: 0.005816063016181923\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "Epoch 284 training complete\n",
      "Cost on training data: 0.0057909675306827705\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 285 training complete\n",
      "Cost on training data: 0.005765711917586898\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 286 training complete\n",
      "Cost on training data: 0.005741114229214293\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 287 training complete\n",
      "Cost on training data: 0.0057164237437494925\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 288 training complete\n",
      "Cost on training data: 0.0056922532540765675\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 289 training complete\n",
      "Cost on training data: 0.005667993731491045\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 290 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 0.0056441129721412665\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 291 training complete\n",
      "Cost on training data: 0.005620365277791484\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 292 training complete\n",
      "Cost on training data: 0.005596594254201795\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 293 training complete\n",
      "Cost on training data: 0.0055732428112902094\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 294 training complete\n",
      "Cost on training data: 0.005550083965435239\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 295 training complete\n",
      "Cost on training data: 0.005526905687477292\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 296 training complete\n",
      "Cost on training data: 0.005504162310759927\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 297 training complete\n",
      "Cost on training data: 0.005481354286618545\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "Epoch 298 training complete\n",
      "Cost on training data: 0.005458828518402086\n",
      "Accuracy on evaluation data: 8120 / 10000\n",
      "Epoch 299 training complete\n",
      "Cost on training data: 0.005436321484160653\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 300 training complete\n",
      "Cost on training data: 0.0054141862598611696\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 301 training complete\n",
      "Cost on training data: 0.0053921878126325755\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 302 training complete\n",
      "Cost on training data: 0.005370218258188465\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 303 training complete\n",
      "Cost on training data: 0.005348412883195309\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 304 training complete\n",
      "Cost on training data: 0.005326795402360275\n",
      "Accuracy on evaluation data: 8119 / 10000\n",
      "Epoch 305 training complete\n",
      "Cost on training data: 0.00530538164782306\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 306 training complete\n",
      "Cost on training data: 0.0052843368605260945\n",
      "Accuracy on evaluation data: 8118 / 10000\n",
      "Epoch 307 training complete\n",
      "Cost on training data: 0.0052630395281983745\n",
      "Accuracy on evaluation data: 8117 / 10000\n",
      "Epoch 308 training complete\n",
      "Cost on training data: 0.0052420448780502015\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 309 training complete\n",
      "Cost on training data: 0.00522140287654406\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 310 training complete\n",
      "Cost on training data: 0.005200893865107584\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 311 training complete\n",
      "Cost on training data: 0.005180324863321342\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 312 training complete\n",
      "Cost on training data: 0.005159843098856877\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 313 training complete\n",
      "Cost on training data: 0.005139640530200379\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 314 training complete\n",
      "Cost on training data: 0.005119684039858808\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 315 training complete\n",
      "Cost on training data: 0.005099670517127759\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 316 training complete\n",
      "Cost on training data: 0.005079900377710282\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 317 training complete\n",
      "Cost on training data: 0.005060423776790109\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 318 training complete\n",
      "Cost on training data: 0.005040809584854803\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 319 training complete\n",
      "Cost on training data: 0.0050216383667702055\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 320 training complete\n",
      "Cost on training data: 0.0050025466705948506\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 321 training complete\n",
      "Cost on training data: 0.004983430001722799\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 322 training complete\n",
      "Cost on training data: 0.004964390816415174\n",
      "Accuracy on evaluation data: 8123 / 10000\n",
      "Epoch 323 training complete\n",
      "Cost on training data: 0.00494566797412255\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 324 training complete\n",
      "Cost on training data: 0.004927105436016572\n",
      "Accuracy on evaluation data: 8121 / 10000\n",
      "Epoch 325 training complete\n",
      "Cost on training data: 0.00490862293477125\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 326 training complete\n",
      "Cost on training data: 0.00489032041544497\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 327 training complete\n",
      "Cost on training data: 0.004872196351523325\n",
      "Accuracy on evaluation data: 8122 / 10000\n",
      "Epoch 328 training complete\n",
      "Cost on training data: 0.004853936897093219\n",
      "Accuracy on evaluation data: 8125 / 10000\n",
      "Epoch 329 training complete\n",
      "Cost on training data: 0.004836030449500773\n",
      "Accuracy on evaluation data: 8126 / 10000\n",
      "Epoch 330 training complete\n",
      "Cost on training data: 0.004818226123481876\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 331 training complete\n",
      "Cost on training data: 0.004800483054643827\n",
      "Accuracy on evaluation data: 8125 / 10000\n",
      "Epoch 332 training complete\n",
      "Cost on training data: 0.004782945188606842\n",
      "Accuracy on evaluation data: 8125 / 10000\n",
      "Epoch 333 training complete\n",
      "Cost on training data: 0.0047655311133248555\n",
      "Accuracy on evaluation data: 8124 / 10000\n",
      "Epoch 334 training complete\n",
      "Cost on training data: 0.004748285141448919\n",
      "Accuracy on evaluation data: 8127 / 10000\n",
      "Epoch 335 training complete\n",
      "Cost on training data: 0.004730971658342972\n",
      "Accuracy on evaluation data: 8126 / 10000\n",
      "Epoch 336 training complete\n",
      "Cost on training data: 0.004713980234657519\n",
      "Accuracy on evaluation data: 8127 / 10000\n",
      "Epoch 337 training complete\n",
      "Cost on training data: 0.004696997679734427\n",
      "Accuracy on evaluation data: 8129 / 10000\n",
      "Epoch 338 training complete\n",
      "Cost on training data: 0.004680205372602699\n",
      "Accuracy on evaluation data: 8131 / 10000\n",
      "Epoch 339 training complete\n",
      "Cost on training data: 0.004663477708066038\n",
      "Accuracy on evaluation data: 8128 / 10000\n",
      "Epoch 340 training complete\n",
      "Cost on training data: 0.004647179633884823\n",
      "Accuracy on evaluation data: 8127 / 10000\n",
      "Epoch 341 training complete\n",
      "Cost on training data: 0.004630384347000152\n",
      "Accuracy on evaluation data: 8128 / 10000\n",
      "Epoch 342 training complete\n",
      "Cost on training data: 0.004614022799738175\n",
      "Accuracy on evaluation data: 8130 / 10000\n",
      "Epoch 343 training complete\n",
      "Cost on training data: 0.004597793667837334\n",
      "Accuracy on evaluation data: 8129 / 10000\n",
      "Epoch 344 training complete\n",
      "Cost on training data: 0.004581725488246214\n",
      "Accuracy on evaluation data: 8130 / 10000\n",
      "Epoch 345 training complete\n",
      "Cost on training data: 0.004565621011030057\n",
      "Accuracy on evaluation data: 8131 / 10000\n",
      "Epoch 346 training complete\n",
      "Cost on training data: 0.004549825445247991\n",
      "Accuracy on evaluation data: 8130 / 10000\n",
      "Epoch 347 training complete\n",
      "Cost on training data: 0.0045342179377569096\n",
      "Accuracy on evaluation data: 8130 / 10000\n",
      "Epoch 348 training complete\n",
      "Cost on training data: 0.00451840865331328\n",
      "Accuracy on evaluation data: 8132 / 10000\n",
      "Epoch 349 training complete\n",
      "Cost on training data: 0.004502721079678097\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 350 training complete\n",
      "Cost on training data: 0.004487361677419386\n",
      "Accuracy on evaluation data: 8131 / 10000\n",
      "Epoch 351 training complete\n",
      "Cost on training data: 0.004471990046838537\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 352 training complete\n",
      "Cost on training data: 0.00445672249617597\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 353 training complete\n",
      "Cost on training data: 0.004441558359454171\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 354 training complete\n",
      "Cost on training data: 0.004426595532194164\n",
      "Accuracy on evaluation data: 8130 / 10000\n",
      "Epoch 355 training complete\n",
      "Cost on training data: 0.004411694601839368\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 356 training complete\n",
      "Cost on training data: 0.004396794977812142\n",
      "Accuracy on evaluation data: 8131 / 10000\n",
      "Epoch 357 training complete\n",
      "Cost on training data: 0.004382085132375055\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 358 training complete\n",
      "Cost on training data: 0.004367478902709396\n",
      "Accuracy on evaluation data: 8131 / 10000\n",
      "Epoch 359 training complete\n",
      "Cost on training data: 0.004352878692017114\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 360 training complete\n",
      "Cost on training data: 0.004338404700780573\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 361 training complete\n",
      "Cost on training data: 0.004324101272211869\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 362 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 0.004309798291942701\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 363 training complete\n",
      "Cost on training data: 0.00429563880056244\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 364 training complete\n",
      "Cost on training data: 0.0042816090837462595\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 365 training complete\n",
      "Cost on training data: 0.004267565707788739\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 366 training complete\n",
      "Cost on training data: 0.004253698098781454\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 367 training complete\n",
      "Cost on training data: 0.00424003701364453\n",
      "Accuracy on evaluation data: 8132 / 10000\n",
      "Epoch 368 training complete\n",
      "Cost on training data: 0.0042261856511886875\n",
      "Accuracy on evaluation data: 8129 / 10000\n",
      "Epoch 369 training complete\n",
      "Cost on training data: 0.004212564685381558\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 370 training complete\n",
      "Cost on training data: 0.0041990169663266835\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 371 training complete\n",
      "Cost on training data: 0.004185557727673396\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 372 training complete\n",
      "Cost on training data: 0.00417218721367652\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 373 training complete\n",
      "Cost on training data: 0.004158894255842717\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 374 training complete\n",
      "Cost on training data: 0.004145713678153875\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 375 training complete\n",
      "Cost on training data: 0.00413260038577147\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 376 training complete\n",
      "Cost on training data: 0.004119562159099068\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 377 training complete\n",
      "Cost on training data: 0.004106770240550851\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 378 training complete\n",
      "Cost on training data: 0.004093724394000052\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 379 training complete\n",
      "Cost on training data: 0.00408081509101199\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 380 training complete\n",
      "Cost on training data: 0.004068138921822991\n",
      "Accuracy on evaluation data: 8133 / 10000\n",
      "Epoch 381 training complete\n",
      "Cost on training data: 0.004055490817291739\n",
      "Accuracy on evaluation data: 8134 / 10000\n",
      "Epoch 382 training complete\n",
      "Cost on training data: 0.004042892603525359\n",
      "Accuracy on evaluation data: 8132 / 10000\n",
      "Epoch 383 training complete\n",
      "Cost on training data: 0.004030361740248878\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 384 training complete\n",
      "Cost on training data: 0.004017952020244151\n",
      "Accuracy on evaluation data: 8137 / 10000\n",
      "Epoch 385 training complete\n",
      "Cost on training data: 0.004005589201370331\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 386 training complete\n",
      "Cost on training data: 0.0039933127987976805\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 387 training complete\n",
      "Cost on training data: 0.003981034333333566\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 388 training complete\n",
      "Cost on training data: 0.003968884029807204\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 389 training complete\n",
      "Cost on training data: 0.003956828331285564\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 390 training complete\n",
      "Cost on training data: 0.003944824588849465\n",
      "Accuracy on evaluation data: 8137 / 10000\n",
      "Epoch 391 training complete\n",
      "Cost on training data: 0.003932908250820637\n",
      "Accuracy on evaluation data: 8137 / 10000\n",
      "Epoch 392 training complete\n",
      "Cost on training data: 0.003920991972229988\n",
      "Accuracy on evaluation data: 8136 / 10000\n",
      "Epoch 393 training complete\n",
      "Cost on training data: 0.003909176427397402\n",
      "Accuracy on evaluation data: 8138 / 10000\n",
      "Epoch 394 training complete\n",
      "Cost on training data: 0.0038974403195570213\n",
      "Accuracy on evaluation data: 8139 / 10000\n",
      "Epoch 395 training complete\n",
      "Cost on training data: 0.0038857728561623992\n",
      "Accuracy on evaluation data: 8138 / 10000\n",
      "Epoch 396 training complete\n",
      "Cost on training data: 0.0038741924160436594\n",
      "Accuracy on evaluation data: 8138 / 10000\n",
      "Epoch 397 training complete\n",
      "Cost on training data: 0.0038626347497764915\n",
      "Accuracy on evaluation data: 8138 / 10000\n",
      "Epoch 398 training complete\n",
      "Cost on training data: 0.0038511368514679294\n",
      "Accuracy on evaluation data: 8139 / 10000\n",
      "Epoch 399 training complete\n",
      "Cost on training data: 0.003839806252280811\n",
      "Accuracy on evaluation data: 8139 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [5343,\n",
       "  6541,\n",
       "  7040,\n",
       "  7139,\n",
       "  7403,\n",
       "  7493,\n",
       "  7667,\n",
       "  7752,\n",
       "  7691,\n",
       "  7835,\n",
       "  7857,\n",
       "  7901,\n",
       "  7899,\n",
       "  7939,\n",
       "  7930,\n",
       "  7982,\n",
       "  7999,\n",
       "  7981,\n",
       "  7972,\n",
       "  7984,\n",
       "  7997,\n",
       "  7989,\n",
       "  8019,\n",
       "  7986,\n",
       "  8043,\n",
       "  8001,\n",
       "  8024,\n",
       "  8047,\n",
       "  8013,\n",
       "  8007,\n",
       "  8014,\n",
       "  8019,\n",
       "  8030,\n",
       "  8016,\n",
       "  8021,\n",
       "  8037,\n",
       "  8048,\n",
       "  8035,\n",
       "  8047,\n",
       "  8034,\n",
       "  8014,\n",
       "  8022,\n",
       "  8011,\n",
       "  8035,\n",
       "  8052,\n",
       "  8056,\n",
       "  8053,\n",
       "  8018,\n",
       "  8023,\n",
       "  8057,\n",
       "  8041,\n",
       "  8063,\n",
       "  8056,\n",
       "  8057,\n",
       "  8061,\n",
       "  8039,\n",
       "  8064,\n",
       "  8055,\n",
       "  8047,\n",
       "  8077,\n",
       "  8049,\n",
       "  8055,\n",
       "  8061,\n",
       "  8059,\n",
       "  8072,\n",
       "  8061,\n",
       "  8060,\n",
       "  8060,\n",
       "  8045,\n",
       "  8061,\n",
       "  8055,\n",
       "  8063,\n",
       "  8063,\n",
       "  8079,\n",
       "  8061,\n",
       "  8058,\n",
       "  8058,\n",
       "  8067,\n",
       "  8060,\n",
       "  8054,\n",
       "  8060,\n",
       "  8060,\n",
       "  8062,\n",
       "  8055,\n",
       "  8071,\n",
       "  8046,\n",
       "  8070,\n",
       "  8050,\n",
       "  8053,\n",
       "  8053,\n",
       "  8066,\n",
       "  8061,\n",
       "  8058,\n",
       "  8063,\n",
       "  8054,\n",
       "  8059,\n",
       "  8050,\n",
       "  8068,\n",
       "  8062,\n",
       "  8064,\n",
       "  8082,\n",
       "  8066,\n",
       "  8063,\n",
       "  8074,\n",
       "  8070,\n",
       "  8071,\n",
       "  8074,\n",
       "  8072,\n",
       "  8073,\n",
       "  8076,\n",
       "  8076,\n",
       "  8078,\n",
       "  8071,\n",
       "  8080,\n",
       "  8081,\n",
       "  8077,\n",
       "  8075,\n",
       "  8076,\n",
       "  8083,\n",
       "  8077,\n",
       "  8082,\n",
       "  8079,\n",
       "  8074,\n",
       "  8078,\n",
       "  8085,\n",
       "  8078,\n",
       "  8074,\n",
       "  8086,\n",
       "  8084,\n",
       "  8082,\n",
       "  8079,\n",
       "  8081,\n",
       "  8089,\n",
       "  8085,\n",
       "  8079,\n",
       "  8086,\n",
       "  8086,\n",
       "  8088,\n",
       "  8093,\n",
       "  8091,\n",
       "  8094,\n",
       "  8090,\n",
       "  8091,\n",
       "  8097,\n",
       "  8092,\n",
       "  8090,\n",
       "  8096,\n",
       "  8089,\n",
       "  8096,\n",
       "  8094,\n",
       "  8090,\n",
       "  8093,\n",
       "  8096,\n",
       "  8092,\n",
       "  8090,\n",
       "  8094,\n",
       "  8095,\n",
       "  8098,\n",
       "  8096,\n",
       "  8098,\n",
       "  8093,\n",
       "  8093,\n",
       "  8094,\n",
       "  8097,\n",
       "  8099,\n",
       "  8098,\n",
       "  8094,\n",
       "  8101,\n",
       "  8094,\n",
       "  8095,\n",
       "  8094,\n",
       "  8089,\n",
       "  8093,\n",
       "  8094,\n",
       "  8095,\n",
       "  8096,\n",
       "  8099,\n",
       "  8096,\n",
       "  8096,\n",
       "  8090,\n",
       "  8090,\n",
       "  8098,\n",
       "  8099,\n",
       "  8104,\n",
       "  8099,\n",
       "  8106,\n",
       "  8101,\n",
       "  8098,\n",
       "  8101,\n",
       "  8102,\n",
       "  8103,\n",
       "  8107,\n",
       "  8104,\n",
       "  8102,\n",
       "  8103,\n",
       "  8101,\n",
       "  8110,\n",
       "  8103,\n",
       "  8102,\n",
       "  8110,\n",
       "  8107,\n",
       "  8104,\n",
       "  8103,\n",
       "  8106,\n",
       "  8107,\n",
       "  8108,\n",
       "  8106,\n",
       "  8106,\n",
       "  8104,\n",
       "  8106,\n",
       "  8108,\n",
       "  8109,\n",
       "  8107,\n",
       "  8106,\n",
       "  8105,\n",
       "  8107,\n",
       "  8109,\n",
       "  8105,\n",
       "  8105,\n",
       "  8105,\n",
       "  8107,\n",
       "  8109,\n",
       "  8110,\n",
       "  8112,\n",
       "  8109,\n",
       "  8111,\n",
       "  8112,\n",
       "  8111,\n",
       "  8113,\n",
       "  8110,\n",
       "  8110,\n",
       "  8112,\n",
       "  8110,\n",
       "  8110,\n",
       "  8112,\n",
       "  8112,\n",
       "  8116,\n",
       "  8116,\n",
       "  8115,\n",
       "  8115,\n",
       "  8113,\n",
       "  8114,\n",
       "  8113,\n",
       "  8115,\n",
       "  8118,\n",
       "  8116,\n",
       "  8114,\n",
       "  8117,\n",
       "  8116,\n",
       "  8117,\n",
       "  8118,\n",
       "  8118,\n",
       "  8117,\n",
       "  8115,\n",
       "  8117,\n",
       "  8116,\n",
       "  8115,\n",
       "  8115,\n",
       "  8116,\n",
       "  8117,\n",
       "  8118,\n",
       "  8120,\n",
       "  8119,\n",
       "  8119,\n",
       "  8118,\n",
       "  8117,\n",
       "  8116,\n",
       "  8115,\n",
       "  8120,\n",
       "  8122,\n",
       "  8121,\n",
       "  8116,\n",
       "  8118,\n",
       "  8115,\n",
       "  8116,\n",
       "  8114,\n",
       "  8116,\n",
       "  8118,\n",
       "  8123,\n",
       "  8119,\n",
       "  8124,\n",
       "  8123,\n",
       "  8122,\n",
       "  8120,\n",
       "  8121,\n",
       "  8121,\n",
       "  8123,\n",
       "  8122,\n",
       "  8118,\n",
       "  8123,\n",
       "  8121,\n",
       "  8121,\n",
       "  8118,\n",
       "  8122,\n",
       "  8117,\n",
       "  8117,\n",
       "  8117,\n",
       "  8120,\n",
       "  8120,\n",
       "  8118,\n",
       "  8121,\n",
       "  8119,\n",
       "  8119,\n",
       "  8118,\n",
       "  8119,\n",
       "  8117,\n",
       "  8118,\n",
       "  8117,\n",
       "  8121,\n",
       "  8123,\n",
       "  8121,\n",
       "  8123,\n",
       "  8123,\n",
       "  8122,\n",
       "  8122,\n",
       "  8122,\n",
       "  8124,\n",
       "  8123,\n",
       "  8122,\n",
       "  8122,\n",
       "  8122,\n",
       "  8124,\n",
       "  8123,\n",
       "  8122,\n",
       "  8121,\n",
       "  8124,\n",
       "  8124,\n",
       "  8122,\n",
       "  8125,\n",
       "  8126,\n",
       "  8124,\n",
       "  8125,\n",
       "  8125,\n",
       "  8124,\n",
       "  8127,\n",
       "  8126,\n",
       "  8127,\n",
       "  8129,\n",
       "  8131,\n",
       "  8128,\n",
       "  8127,\n",
       "  8128,\n",
       "  8130,\n",
       "  8129,\n",
       "  8130,\n",
       "  8131,\n",
       "  8130,\n",
       "  8130,\n",
       "  8132,\n",
       "  8134,\n",
       "  8131,\n",
       "  8133,\n",
       "  8133,\n",
       "  8134,\n",
       "  8130,\n",
       "  8134,\n",
       "  8131,\n",
       "  8133,\n",
       "  8131,\n",
       "  8133,\n",
       "  8135,\n",
       "  8133,\n",
       "  8134,\n",
       "  8135,\n",
       "  8134,\n",
       "  8133,\n",
       "  8133,\n",
       "  8132,\n",
       "  8129,\n",
       "  8134,\n",
       "  8134,\n",
       "  8134,\n",
       "  8134,\n",
       "  8135,\n",
       "  8133,\n",
       "  8134,\n",
       "  8136,\n",
       "  8134,\n",
       "  8136,\n",
       "  8134,\n",
       "  8133,\n",
       "  8134,\n",
       "  8132,\n",
       "  8136,\n",
       "  8137,\n",
       "  8136,\n",
       "  8135,\n",
       "  8135,\n",
       "  8136,\n",
       "  8135,\n",
       "  8137,\n",
       "  8137,\n",
       "  8136,\n",
       "  8138,\n",
       "  8139,\n",
       "  8138,\n",
       "  8138,\n",
       "  8138,\n",
       "  8139,\n",
       "  8139],\n",
       " [2.0372940736184462,\n",
       "  1.4665988601274971,\n",
       "  1.2094834221751929,\n",
       "  1.0386860426367834,\n",
       "  0.88286153282383206,\n",
       "  0.77909771802970851,\n",
       "  0.69356960784396193,\n",
       "  0.59371765377868191,\n",
       "  0.55584373253903874,\n",
       "  0.49369697816786062,\n",
       "  0.44093412494643974,\n",
       "  0.41097588502455035,\n",
       "  0.36099438790661753,\n",
       "  0.33559712594218988,\n",
       "  0.32218311655730636,\n",
       "  0.287654779216103,\n",
       "  0.26679971397381624,\n",
       "  0.25065770990281633,\n",
       "  0.22970728759290684,\n",
       "  0.22107139673672041,\n",
       "  0.20535108077423825,\n",
       "  0.19335939020634235,\n",
       "  0.18126270572980432,\n",
       "  0.17439471460788653,\n",
       "  0.16256449668317613,\n",
       "  0.15748352884280237,\n",
       "  0.14612694009913618,\n",
       "  0.13935406401829797,\n",
       "  0.13306113281194376,\n",
       "  0.12750815774784222,\n",
       "  0.12187446376267563,\n",
       "  0.11616684688154032,\n",
       "  0.11242925917101829,\n",
       "  0.10846760323678388,\n",
       "  0.1040086027662091,\n",
       "  0.099679766996052549,\n",
       "  0.096816780724627099,\n",
       "  0.093108632032776389,\n",
       "  0.089667228928192705,\n",
       "  0.087341395311175823,\n",
       "  0.084210120812645464,\n",
       "  0.080940927983757072,\n",
       "  0.080769730669478526,\n",
       "  0.076486078319932385,\n",
       "  0.075389784242605187,\n",
       "  0.071615030215206904,\n",
       "  0.069795604069218253,\n",
       "  0.067512085586656348,\n",
       "  0.064959025759579431,\n",
       "  0.062704902032129806,\n",
       "  0.061226396919914279,\n",
       "  0.059577451796716765,\n",
       "  0.057833539730017362,\n",
       "  0.056222658596012678,\n",
       "  0.054880996620226975,\n",
       "  0.053843708848171634,\n",
       "  0.052632211051569233,\n",
       "  0.050988699608469121,\n",
       "  0.050044543763605474,\n",
       "  0.048779030440527081,\n",
       "  0.048173000149151227,\n",
       "  0.046575495637144956,\n",
       "  0.045492418647979108,\n",
       "  0.044363446671938409,\n",
       "  0.043469155503370459,\n",
       "  0.042531601052889875,\n",
       "  0.041492791764111893,\n",
       "  0.040694583726512468,\n",
       "  0.03991689290647326,\n",
       "  0.039031074151149842,\n",
       "  0.038231034060128788,\n",
       "  0.037514967297606262,\n",
       "  0.036832974997745765,\n",
       "  0.036313347107492656,\n",
       "  0.035538566283575976,\n",
       "  0.034862797587626004,\n",
       "  0.034137080990976204,\n",
       "  0.033525132770197974,\n",
       "  0.033031238014724795,\n",
       "  0.032368150903109322,\n",
       "  0.031767258470523224,\n",
       "  0.03114484877357657,\n",
       "  0.03059858846188776,\n",
       "  0.03005221734769702,\n",
       "  0.029540164139028907,\n",
       "  0.029202260313432021,\n",
       "  0.028554287883843579,\n",
       "  0.028107100700160779,\n",
       "  0.027605473569881821,\n",
       "  0.027124154432859475,\n",
       "  0.026610879564615442,\n",
       "  0.026151874140764302,\n",
       "  0.025705930091880325,\n",
       "  0.025304423458804758,\n",
       "  0.024851046127933592,\n",
       "  0.024400789698142567,\n",
       "  0.024045877937110698,\n",
       "  0.023636551500097146,\n",
       "  0.02321164104731049,\n",
       "  0.022874749812631771,\n",
       "  0.022552708371968315,\n",
       "  0.022205054754696165,\n",
       "  0.021872266491140529,\n",
       "  0.021541762858940432,\n",
       "  0.021232402141143709,\n",
       "  0.02094585033567101,\n",
       "  0.020668272365088655,\n",
       "  0.020397955049272755,\n",
       "  0.020131060828968116,\n",
       "  0.019873591373278956,\n",
       "  0.019630414922463701,\n",
       "  0.019399912569147689,\n",
       "  0.019151976796030184,\n",
       "  0.018940656523688884,\n",
       "  0.018703531575515606,\n",
       "  0.018491898604476573,\n",
       "  0.018286754974806474,\n",
       "  0.018072006492734601,\n",
       "  0.0178684464427541,\n",
       "  0.017671404457560446,\n",
       "  0.017474745022920634,\n",
       "  0.017288760293943047,\n",
       "  0.017105952272357408,\n",
       "  0.016933651239436541,\n",
       "  0.016746541657554476,\n",
       "  0.016581670343325475,\n",
       "  0.01640747349453707,\n",
       "  0.016241260742336519,\n",
       "  0.016084514413599288,\n",
       "  0.015912789025852428,\n",
       "  0.015754518947854526,\n",
       "  0.015607334841301434,\n",
       "  0.015452438193206193,\n",
       "  0.015305876740787941,\n",
       "  0.015164763148056386,\n",
       "  0.015016129443531265,\n",
       "  0.014874245974003913,\n",
       "  0.014733868434479448,\n",
       "  0.014593980479828119,\n",
       "  0.014465228195940243,\n",
       "  0.014336569435624093,\n",
       "  0.014192132224060601,\n",
       "  0.014065785130490357,\n",
       "  0.013936745792577617,\n",
       "  0.013815733713413431,\n",
       "  0.013686658027460843,\n",
       "  0.013563067561822854,\n",
       "  0.013441785197345372,\n",
       "  0.013326910717478978,\n",
       "  0.013203526333499216,\n",
       "  0.013085236139448174,\n",
       "  0.012967735863243747,\n",
       "  0.01285333457877356,\n",
       "  0.012741963555535335,\n",
       "  0.012632994146132042,\n",
       "  0.012517953410473213,\n",
       "  0.012413457900446748,\n",
       "  0.012300859471193495,\n",
       "  0.012197779490593636,\n",
       "  0.012096335713110334,\n",
       "  0.011991413722200398,\n",
       "  0.011888241819214449,\n",
       "  0.011790158542976523,\n",
       "  0.01169661741974759,\n",
       "  0.0115956408046912,\n",
       "  0.011498777442270094,\n",
       "  0.011408074538770662,\n",
       "  0.011313177446191159,\n",
       "  0.011220552282563552,\n",
       "  0.011134036464036743,\n",
       "  0.011044699651372685,\n",
       "  0.010962641897427504,\n",
       "  0.010871056305820153,\n",
       "  0.010787620259445971,\n",
       "  0.010707881323061684,\n",
       "  0.010627482587982778,\n",
       "  0.010546156160922072,\n",
       "  0.010466851041727926,\n",
       "  0.010388518886649455,\n",
       "  0.010315034734019797,\n",
       "  0.010236728286837535,\n",
       "  0.010162386349029155,\n",
       "  0.010089111881778325,\n",
       "  0.010018200765469023,\n",
       "  0.0099493959097603935,\n",
       "  0.0098770986078006717,\n",
       "  0.0098075163556636674,\n",
       "  0.0097423545246659877,\n",
       "  0.0096734320515911767,\n",
       "  0.009609146260113095,\n",
       "  0.0095424548058389222,\n",
       "  0.0094770595786108358,\n",
       "  0.0094131755226924685,\n",
       "  0.0093519393293542002,\n",
       "  0.0092893872904630005,\n",
       "  0.0092291304244052786,\n",
       "  0.0091688014148267605,\n",
       "  0.0091087030404303476,\n",
       "  0.0090516423987885165,\n",
       "  0.0089919627907316096,\n",
       "  0.0089349087770815572,\n",
       "  0.0088812119696276975,\n",
       "  0.0088280534580839187,\n",
       "  0.0087696669257607412,\n",
       "  0.0087158738814710653,\n",
       "  0.0086612132662617202,\n",
       "  0.0086077689159139697,\n",
       "  0.008555755034483482,\n",
       "  0.008503346679783523,\n",
       "  0.0084526982507600219,\n",
       "  0.0084017730719753228,\n",
       "  0.0083526571449356359,\n",
       "  0.0083040290172222038,\n",
       "  0.0082546916962462583,\n",
       "  0.008205490466563466,\n",
       "  0.0081581513352055168,\n",
       "  0.0081106714908298454,\n",
       "  0.0080652849154513422,\n",
       "  0.0080188636056531138,\n",
       "  0.0079730139840257664,\n",
       "  0.0079286325116463777,\n",
       "  0.0078841421334504332,\n",
       "  0.0078394017669926857,\n",
       "  0.0077955019918271385,\n",
       "  0.0077522806957565915,\n",
       "  0.0077099903112721095,\n",
       "  0.0076676074848183512,\n",
       "  0.0076262765139854215,\n",
       "  0.0075847705357521937,\n",
       "  0.0075434802761181786,\n",
       "  0.0075024925661228503,\n",
       "  0.0074631153666743786,\n",
       "  0.007423017899695742,\n",
       "  0.0073840180251557802,\n",
       "  0.0073448125925795714,\n",
       "  0.0073064675088149768,\n",
       "  0.0072681156664966265,\n",
       "  0.0072306097402962538,\n",
       "  0.007192958952614471,\n",
       "  0.0071560612218202211,\n",
       "  0.0071196038300890239,\n",
       "  0.0070831352291529969,\n",
       "  0.0070468824693101558,\n",
       "  0.0070113046752963348,\n",
       "  0.0069764612454623126,\n",
       "  0.0069412360017252813,\n",
       "  0.0069072246485177456,\n",
       "  0.0068723831295579548,\n",
       "  0.0068382062234410403,\n",
       "  0.0068048719148279778,\n",
       "  0.0067714921900592232,\n",
       "  0.0067381696988025735,\n",
       "  0.0067051044490452306,\n",
       "  0.0066731993906661872,\n",
       "  0.0066402098974698981,\n",
       "  0.0066084772132389029,\n",
       "  0.0065768101460235793,\n",
       "  0.0065456083039449652,\n",
       "  0.0065147549078521444,\n",
       "  0.0064834685668406699,\n",
       "  0.006453053806082772,\n",
       "  0.0064229031745692304,\n",
       "  0.0063926808394844034,\n",
       "  0.0063629020622164934,\n",
       "  0.006333235900405374,\n",
       "  0.0063041618628245158,\n",
       "  0.0062751868585244255,\n",
       "  0.0062468844532259458,\n",
       "  0.0062175884108311629,\n",
       "  0.006189064483143848,\n",
       "  0.0061610332118341403,\n",
       "  0.0061333847776983072,\n",
       "  0.0061054443470701216,\n",
       "  0.0060782636554086583,\n",
       "  0.00605091059397615,\n",
       "  0.0060245860875381384,\n",
       "  0.0059972367069415656,\n",
       "  0.0059709016872859788,\n",
       "  0.0059444214472065453,\n",
       "  0.0059184421964943446,\n",
       "  0.0058922217232464926,\n",
       "  0.0058667993425521878,\n",
       "  0.0058414799339999626,\n",
       "  0.0058160630161819228,\n",
       "  0.0057909675306827705,\n",
       "  0.0057657119175868977,\n",
       "  0.0057411142292142928,\n",
       "  0.0057164237437494925,\n",
       "  0.0056922532540765675,\n",
       "  0.0056679937314910453,\n",
       "  0.0056441129721412665,\n",
       "  0.0056203652777914838,\n",
       "  0.0055965942542017949,\n",
       "  0.0055732428112902094,\n",
       "  0.0055500839654352386,\n",
       "  0.0055269056874772916,\n",
       "  0.0055041623107599273,\n",
       "  0.0054813542866185448,\n",
       "  0.0054588285184020858,\n",
       "  0.0054363214841606526,\n",
       "  0.0054141862598611696,\n",
       "  0.0053921878126325755,\n",
       "  0.0053702182581884649,\n",
       "  0.0053484128831953089,\n",
       "  0.0053267954023602749,\n",
       "  0.0053053816478230596,\n",
       "  0.0052843368605260945,\n",
       "  0.0052630395281983745,\n",
       "  0.0052420448780502015,\n",
       "  0.0052214028765440604,\n",
       "  0.0052008938651075844,\n",
       "  0.0051803248633213424,\n",
       "  0.0051598430988568766,\n",
       "  0.0051396405302003793,\n",
       "  0.0051196840398588083,\n",
       "  0.0050996705171277587,\n",
       "  0.0050799003777102824,\n",
       "  0.0050604237767901093,\n",
       "  0.0050408095848548029,\n",
       "  0.0050216383667702055,\n",
       "  0.0050025466705948506,\n",
       "  0.0049834300017227986,\n",
       "  0.0049643908164151741,\n",
       "  0.0049456679741225499,\n",
       "  0.004927105436016572,\n",
       "  0.0049086229347712496,\n",
       "  0.0048903204154449702,\n",
       "  0.0048721963515233249,\n",
       "  0.0048539368970932188,\n",
       "  0.0048360304495007733,\n",
       "  0.0048182261234818759,\n",
       "  0.0048004830546438271,\n",
       "  0.0047829451886068422,\n",
       "  0.0047655311133248555,\n",
       "  0.0047482851414489191,\n",
       "  0.0047309716583429718,\n",
       "  0.0047139802346575187,\n",
       "  0.0046969976797344272,\n",
       "  0.0046802053726026993,\n",
       "  0.0046634777080660382,\n",
       "  0.0046471796338848226,\n",
       "  0.0046303843470001521,\n",
       "  0.0046140227997381747,\n",
       "  0.0045977936678373342,\n",
       "  0.0045817254882462143,\n",
       "  0.0045656210110300568,\n",
       "  0.0045498254452479908,\n",
       "  0.0045342179377569096,\n",
       "  0.00451840865331328,\n",
       "  0.0045027210796780969,\n",
       "  0.0044873616774193858,\n",
       "  0.0044719900468385369,\n",
       "  0.0044567224961759699,\n",
       "  0.0044415583594541713,\n",
       "  0.0044265955321941639,\n",
       "  0.0044116946018393681,\n",
       "  0.0043967949778121419,\n",
       "  0.0043820851323750553,\n",
       "  0.0043674789027093961,\n",
       "  0.0043528786920171139,\n",
       "  0.004338404700780573,\n",
       "  0.0043241012722118688,\n",
       "  0.004309798291942701,\n",
       "  0.0042956388005624402,\n",
       "  0.0042816090837462595,\n",
       "  0.0042675657077887392,\n",
       "  0.0042536980987814537,\n",
       "  0.0042400370136445303,\n",
       "  0.0042261856511886875,\n",
       "  0.0042125646853815582,\n",
       "  0.0041990169663266835,\n",
       "  0.0041855577276733958,\n",
       "  0.00417218721367652,\n",
       "  0.0041588942558427166,\n",
       "  0.0041457136781538747,\n",
       "  0.0041326003857714696,\n",
       "  0.0041195621590990683,\n",
       "  0.004106770240550851,\n",
       "  0.0040937243940000522,\n",
       "  0.0040808150910119903,\n",
       "  0.004068138921822991,\n",
       "  0.0040554908172917388,\n",
       "  0.0040428926035253592,\n",
       "  0.0040303617402488784,\n",
       "  0.004017952020244151,\n",
       "  0.0040055892013703314,\n",
       "  0.0039933127987976805,\n",
       "  0.0039810343333335661,\n",
       "  0.0039688840298072042,\n",
       "  0.003956828331285564,\n",
       "  0.0039448245888494653,\n",
       "  0.0039329082508206374,\n",
       "  0.0039209919722299879,\n",
       "  0.0039091764273974016,\n",
       "  0.0038974403195570213,\n",
       "  0.0038857728561623992,\n",
       "  0.0038741924160436594,\n",
       "  0.0038626347497764915,\n",
       "  0.0038511368514679294,\n",
       "  0.0038398062522808111],\n",
       " [])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist_loader \n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2 \n",
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost) \n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, monitor_evaluation_accuracy=True, monitor_training_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Cost on training data: 1189.8963049138863\n",
      "Accuracy on training data: 678 / 1000\n",
      "Cost on evaluation data: 1190.2131408750452\n",
      "Accuracy on evaluation data: 5766 / 10000\n",
      "Epoch 1 training complete\n",
      "Cost on training data: 1179.4899479972705\n",
      "Accuracy on training data: 789 / 1000\n",
      "Cost on evaluation data: 1179.9817978897381\n",
      "Accuracy on evaluation data: 6648 / 10000\n",
      "Epoch 2 training complete\n",
      "Cost on training data: 1169.800905484714\n",
      "Accuracy on training data: 841 / 1000\n",
      "Cost on evaluation data: 1170.3228776087863\n",
      "Accuracy on evaluation data: 7142 / 10000\n",
      "Epoch 3 training complete\n",
      "Cost on training data: 1160.5152478984442\n",
      "Accuracy on training data: 875 / 1000\n",
      "Cost on evaluation data: 1161.1002332615305\n",
      "Accuracy on evaluation data: 7290 / 10000\n",
      "Epoch 4 training complete\n",
      "Cost on training data: 1151.38390766804\n",
      "Accuracy on training data: 910 / 1000\n",
      "Cost on evaluation data: 1152.0053503669774\n",
      "Accuracy on evaluation data: 7548 / 10000\n",
      "Epoch 5 training complete\n",
      "Cost on training data: 1142.2816102989132\n",
      "Accuracy on training data: 928 / 1000\n",
      "Cost on evaluation data: 1142.957824827503\n",
      "Accuracy on evaluation data: 7755 / 10000\n",
      "Epoch 6 training complete\n",
      "Cost on training data: 1133.3873448200952\n",
      "Accuracy on training data: 946 / 1000\n",
      "Cost on evaluation data: 1134.0939970523755\n",
      "Accuracy on evaluation data: 7787 / 10000\n",
      "Epoch 7 training complete\n",
      "Cost on training data: 1124.4831091782055\n",
      "Accuracy on training data: 952 / 1000\n",
      "Cost on evaluation data: 1125.2261963374467\n",
      "Accuracy on evaluation data: 7927 / 10000\n",
      "Epoch 8 training complete\n",
      "Cost on training data: 1115.603520169226\n",
      "Accuracy on training data: 949 / 1000\n",
      "Cost on evaluation data: 1116.397893036427\n",
      "Accuracy on evaluation data: 7909 / 10000\n",
      "Epoch 9 training complete\n",
      "Cost on training data: 1106.8270841844212\n",
      "Accuracy on training data: 955 / 1000\n",
      "Cost on evaluation data: 1107.6156480393236\n",
      "Accuracy on evaluation data: 8044 / 10000\n",
      "Epoch 10 training complete\n",
      "Cost on training data: 1098.1239581612267\n",
      "Accuracy on training data: 962 / 1000\n",
      "Cost on evaluation data: 1098.9858198529062\n",
      "Accuracy on evaluation data: 7965 / 10000\n",
      "Epoch 11 training complete\n",
      "Cost on training data: 1089.3982257868204\n",
      "Accuracy on training data: 967 / 1000\n",
      "Cost on evaluation data: 1090.2365807240471\n",
      "Accuracy on evaluation data: 8077 / 10000\n",
      "Epoch 12 training complete\n",
      "Cost on training data: 1080.7173773698046\n",
      "Accuracy on training data: 967 / 1000\n",
      "Cost on evaluation data: 1081.5856522769986\n",
      "Accuracy on evaluation data: 8090 / 10000\n",
      "Epoch 13 training complete\n",
      "Cost on training data: 1072.0783346264\n",
      "Accuracy on training data: 971 / 1000\n",
      "Cost on evaluation data: 1072.968130421364\n",
      "Accuracy on evaluation data: 8091 / 10000\n",
      "Epoch 14 training complete\n",
      "Cost on training data: 1063.4373496708977\n",
      "Accuracy on training data: 975 / 1000\n",
      "Cost on evaluation data: 1064.330424011274\n",
      "Accuracy on evaluation data: 8139 / 10000\n",
      "Epoch 15 training complete\n",
      "Cost on training data: 1054.8715281466875\n",
      "Accuracy on training data: 975 / 1000\n",
      "Cost on evaluation data: 1055.7750109424658\n",
      "Accuracy on evaluation data: 8152 / 10000\n",
      "Epoch 16 training complete\n",
      "Cost on training data: 1046.294394848376\n",
      "Accuracy on training data: 979 / 1000\n",
      "Cost on evaluation data: 1047.2240572271655\n",
      "Accuracy on evaluation data: 8135 / 10000\n",
      "Epoch 17 training complete\n",
      "Cost on training data: 1037.864683474748\n",
      "Accuracy on training data: 981 / 1000\n",
      "Cost on evaluation data: 1038.7874364462189\n",
      "Accuracy on evaluation data: 8169 / 10000\n",
      "Epoch 18 training complete\n",
      "Cost on training data: 1029.387272947334\n",
      "Accuracy on training data: 983 / 1000\n",
      "Cost on evaluation data: 1030.3538674696615\n",
      "Accuracy on evaluation data: 8157 / 10000\n",
      "Epoch 19 training complete\n",
      "Cost on training data: 1020.96448840489\n",
      "Accuracy on training data: 986 / 1000\n",
      "Cost on evaluation data: 1021.9237389072792\n",
      "Accuracy on evaluation data: 8201 / 10000\n",
      "Epoch 20 training complete\n",
      "Cost on training data: 1012.5912464995713\n",
      "Accuracy on training data: 986 / 1000\n",
      "Cost on evaluation data: 1013.5806673367566\n",
      "Accuracy on evaluation data: 8186 / 10000\n",
      "Epoch 21 training complete\n",
      "Cost on training data: 1004.2677059041679\n",
      "Accuracy on training data: 988 / 1000\n",
      "Cost on evaluation data: 1005.255398595949\n",
      "Accuracy on evaluation data: 8174 / 10000\n",
      "Epoch 22 training complete\n",
      "Cost on training data: 995.9925616972874\n",
      "Accuracy on training data: 984 / 1000\n",
      "Cost on evaluation data: 996.9774342752673\n",
      "Accuracy on evaluation data: 8184 / 10000\n",
      "Epoch 23 training complete\n",
      "Cost on training data: 987.7521619865964\n",
      "Accuracy on training data: 990 / 1000\n",
      "Cost on evaluation data: 988.7405125884512\n",
      "Accuracy on evaluation data: 8206 / 10000\n",
      "Epoch 24 training complete\n",
      "Cost on training data: 979.5703090864406\n",
      "Accuracy on training data: 990 / 1000\n",
      "Cost on evaluation data: 980.5759651780409\n",
      "Accuracy on evaluation data: 8239 / 10000\n",
      "Epoch 25 training complete\n",
      "Cost on training data: 971.4278432767189\n",
      "Accuracy on training data: 991 / 1000\n",
      "Cost on evaluation data: 972.4288051193912\n",
      "Accuracy on evaluation data: 8241 / 10000\n",
      "Epoch 26 training complete\n",
      "Cost on training data: 963.3379763252261\n",
      "Accuracy on training data: 992 / 1000\n",
      "Cost on evaluation data: 964.3568689431477\n",
      "Accuracy on evaluation data: 8249 / 10000\n",
      "Epoch 27 training complete\n",
      "Cost on training data: 955.3006517776262\n",
      "Accuracy on training data: 992 / 1000\n",
      "Cost on evaluation data: 956.320476215472\n",
      "Accuracy on evaluation data: 8243 / 10000\n",
      "Epoch 28 training complete\n",
      "Cost on training data: 947.3208067385813\n",
      "Accuracy on training data: 992 / 1000\n",
      "Cost on evaluation data: 948.3479084158852\n",
      "Accuracy on evaluation data: 8248 / 10000\n",
      "Epoch 29 training complete\n",
      "Cost on training data: 939.3532741092865\n",
      "Accuracy on training data: 993 / 1000\n",
      "Cost on evaluation data: 940.3984042664908\n",
      "Accuracy on evaluation data: 8250 / 10000\n",
      "Epoch 30 training complete\n",
      "Cost on training data: 931.4595209162492\n",
      "Accuracy on training data: 993 / 1000\n",
      "Cost on evaluation data: 932.505059895911\n",
      "Accuracy on evaluation data: 8259 / 10000\n",
      "Epoch 31 training complete\n",
      "Cost on training data: 923.6176036904626\n",
      "Accuracy on training data: 993 / 1000\n",
      "Cost on evaluation data: 924.6595216796048\n",
      "Accuracy on evaluation data: 8267 / 10000\n",
      "Epoch 32 training complete\n",
      "Cost on training data: 915.8730941025401\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 916.9226275171933\n",
      "Accuracy on evaluation data: 8242 / 10000\n",
      "Epoch 33 training complete\n",
      "Cost on training data: 908.1485875339515\n",
      "Accuracy on training data: 994 / 1000\n",
      "Cost on evaluation data: 909.213713080792\n",
      "Accuracy on evaluation data: 8278 / 10000\n",
      "Epoch 34 training complete\n",
      "Cost on training data: 900.5358751971987\n",
      "Accuracy on training data: 995 / 1000\n",
      "Cost on evaluation data: 901.5957666543333\n",
      "Accuracy on evaluation data: 8275 / 10000\n",
      "Epoch 35 training complete\n",
      "Cost on training data: 892.9581495523524\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 894.0283291452599\n",
      "Accuracy on evaluation data: 8284 / 10000\n",
      "Epoch 36 training complete\n",
      "Cost on training data: 885.4372531032217\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 886.5223970268385\n",
      "Accuracy on evaluation data: 8278 / 10000\n",
      "Epoch 37 training complete\n",
      "Cost on training data: 877.9703993636371\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 879.0557988529227\n",
      "Accuracy on evaluation data: 8273 / 10000\n",
      "Epoch 38 training complete\n",
      "Cost on training data: 870.5520272454723\n",
      "Accuracy on training data: 996 / 1000\n",
      "Cost on evaluation data: 871.6349994831387\n",
      "Accuracy on evaluation data: 8286 / 10000\n",
      "Epoch 39 training complete\n",
      "Cost on training data: 863.2169546755758\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 864.2929876312512\n",
      "Accuracy on evaluation data: 8297 / 10000\n",
      "Epoch 40 training complete\n",
      "Cost on training data: 855.9373051117243\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 857.0154839118059\n",
      "Accuracy on evaluation data: 8307 / 10000\n",
      "Epoch 41 training complete\n",
      "Cost on training data: 848.6871501919012\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 849.7666831225404\n",
      "Accuracy on evaluation data: 8325 / 10000\n",
      "Epoch 42 training complete\n",
      "Cost on training data: 841.4946295044739\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 842.5803098499337\n",
      "Accuracy on evaluation data: 8315 / 10000\n",
      "Epoch 43 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 834.347725501532\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 835.4491918674424\n",
      "Accuracy on evaluation data: 8300 / 10000\n",
      "Epoch 44 training complete\n",
      "Cost on training data: 827.2528937507867\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 828.3477850305641\n",
      "Accuracy on evaluation data: 8313 / 10000\n",
      "Epoch 45 training complete\n",
      "Cost on training data: 820.2309361057773\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 821.3242705855746\n",
      "Accuracy on evaluation data: 8307 / 10000\n",
      "Epoch 46 training complete\n",
      "Cost on training data: 813.2540985215999\n",
      "Accuracy on training data: 997 / 1000\n",
      "Cost on evaluation data: 814.3446083090801\n",
      "Accuracy on evaluation data: 8329 / 10000\n",
      "Epoch 47 training complete\n",
      "Cost on training data: 806.3439449242177\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 807.4390971378997\n",
      "Accuracy on evaluation data: 8343 / 10000\n",
      "Epoch 48 training complete\n",
      "Cost on training data: 799.4908668259817\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 800.5938797716007\n",
      "Accuracy on evaluation data: 8338 / 10000\n",
      "Epoch 49 training complete\n",
      "Cost on training data: 792.7113600630283\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 793.8175746665468\n",
      "Accuracy on evaluation data: 8322 / 10000\n",
      "Epoch 50 training complete\n",
      "Cost on training data: 785.958950256743\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 787.0579240176241\n",
      "Accuracy on evaluation data: 8363 / 10000\n",
      "Epoch 51 training complete\n",
      "Cost on training data: 779.2769667620587\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 780.3780972484213\n",
      "Accuracy on evaluation data: 8364 / 10000\n",
      "Epoch 52 training complete\n",
      "Cost on training data: 772.639921116048\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 773.7564627698115\n",
      "Accuracy on evaluation data: 8335 / 10000\n",
      "Epoch 53 training complete\n",
      "Cost on training data: 766.0672684826097\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 767.1760959483975\n",
      "Accuracy on evaluation data: 8349 / 10000\n",
      "Epoch 54 training complete\n",
      "Cost on training data: 759.5403696386263\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 760.6378900225147\n",
      "Accuracy on evaluation data: 8370 / 10000\n",
      "Epoch 55 training complete\n",
      "Cost on training data: 753.0607752919775\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 754.1667110440874\n",
      "Accuracy on evaluation data: 8375 / 10000\n",
      "Epoch 56 training complete\n",
      "Cost on training data: 746.6408706830442\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 747.7455041142863\n",
      "Accuracy on evaluation data: 8382 / 10000\n",
      "Epoch 57 training complete\n",
      "Cost on training data: 740.2818904691728\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 741.3858924805836\n",
      "Accuracy on evaluation data: 8383 / 10000\n",
      "Epoch 58 training complete\n",
      "Cost on training data: 733.962811401811\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 735.0738139471661\n",
      "Accuracy on evaluation data: 8379 / 10000\n",
      "Epoch 59 training complete\n",
      "Cost on training data: 727.7059179648671\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 728.8222223727315\n",
      "Accuracy on evaluation data: 8384 / 10000\n",
      "Epoch 60 training complete\n",
      "Cost on training data: 721.5038901922059\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 722.6225818165258\n",
      "Accuracy on evaluation data: 8373 / 10000\n",
      "Epoch 61 training complete\n",
      "Cost on training data: 715.3617740796956\n",
      "Accuracy on training data: 998 / 1000\n",
      "Cost on evaluation data: 716.4704426695738\n",
      "Accuracy on evaluation data: 8381 / 10000\n",
      "Epoch 62 training complete\n",
      "Cost on training data: 709.2505032238711\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 710.3609856446951\n",
      "Accuracy on evaluation data: 8401 / 10000\n",
      "Epoch 63 training complete\n",
      "Cost on training data: 703.2154555167346\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 704.3216318721448\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "Epoch 64 training complete\n",
      "Cost on training data: 697.2277728806482\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 698.3355197238151\n",
      "Accuracy on evaluation data: 8404 / 10000\n",
      "Epoch 65 training complete\n",
      "Cost on training data: 691.2770182442176\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 692.3884585219103\n",
      "Accuracy on evaluation data: 8391 / 10000\n",
      "Epoch 66 training complete\n",
      "Cost on training data: 685.3886874158836\n",
      "Accuracy on training data: 999 / 1000\n",
      "Cost on evaluation data: 686.5018182013557\n",
      "Accuracy on evaluation data: 8388 / 10000\n",
      "Epoch 67 training complete\n",
      "Cost on training data: 679.5629839305032\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 680.6719383587072\n",
      "Accuracy on evaluation data: 8403 / 10000\n",
      "Epoch 68 training complete\n",
      "Cost on training data: 673.7897078231356\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 674.9012340679511\n",
      "Accuracy on evaluation data: 8383 / 10000\n",
      "Epoch 69 training complete\n",
      "Cost on training data: 668.0536406804747\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 669.1597815137734\n",
      "Accuracy on evaluation data: 8398 / 10000\n",
      "Epoch 70 training complete\n",
      "Cost on training data: 662.3902406337552\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 663.4932559888608\n",
      "Accuracy on evaluation data: 8413 / 10000\n",
      "Epoch 71 training complete\n",
      "Cost on training data: 656.755502001453\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 657.8692174435157\n",
      "Accuracy on evaluation data: 8395 / 10000\n",
      "Epoch 72 training complete\n",
      "Cost on training data: 651.1718610597338\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 652.2708519902563\n",
      "Accuracy on evaluation data: 8427 / 10000\n",
      "Epoch 73 training complete\n",
      "Cost on training data: 645.630632606329\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 646.7387326039607\n",
      "Accuracy on evaluation data: 8423 / 10000\n",
      "Epoch 74 training complete\n",
      "Cost on training data: 640.1438802381349\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 641.2530194291164\n",
      "Accuracy on evaluation data: 8420 / 10000\n",
      "Epoch 75 training complete\n",
      "Cost on training data: 634.707762709674\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 635.814456952504\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "Epoch 76 training complete\n",
      "Cost on training data: 629.3139893759978\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 630.4180444089034\n",
      "Accuracy on evaluation data: 8435 / 10000\n",
      "Epoch 77 training complete\n",
      "Cost on training data: 623.9759229198571\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 625.0851396090452\n",
      "Accuracy on evaluation data: 8428 / 10000\n",
      "Epoch 78 training complete\n",
      "Cost on training data: 618.6804618622803\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 619.7822724581458\n",
      "Accuracy on evaluation data: 8442 / 10000\n",
      "Epoch 79 training complete\n",
      "Cost on training data: 613.4362958541257\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 614.5327389759561\n",
      "Accuracy on evaluation data: 8431 / 10000\n",
      "Epoch 80 training complete\n",
      "Cost on training data: 608.2327434185366\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 609.334774557876\n",
      "Accuracy on evaluation data: 8438 / 10000\n",
      "Epoch 81 training complete\n",
      "Cost on training data: 603.0822821516689\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 604.1863451549261\n",
      "Accuracy on evaluation data: 8443 / 10000\n",
      "Epoch 82 training complete\n",
      "Cost on training data: 597.9753035686543\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 599.0741199370981\n",
      "Accuracy on evaluation data: 8439 / 10000\n",
      "Epoch 83 training complete\n",
      "Cost on training data: 592.9176165614844\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 594.0137065623358\n",
      "Accuracy on evaluation data: 8442 / 10000\n",
      "Epoch 84 training complete\n",
      "Cost on training data: 587.8978732753548\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 588.9986773224438\n",
      "Accuracy on evaluation data: 8453 / 10000\n",
      "Epoch 85 training complete\n",
      "Cost on training data: 582.9299549613438\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 584.0332064105636\n",
      "Accuracy on evaluation data: 8447 / 10000\n",
      "Epoch 86 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 578.002722632971\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 579.0958307454226\n",
      "Accuracy on evaluation data: 8457 / 10000\n",
      "Epoch 87 training complete\n",
      "Cost on training data: 573.1269517531925\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 574.2241009482061\n",
      "Accuracy on evaluation data: 8450 / 10000\n",
      "Epoch 88 training complete\n",
      "Cost on training data: 568.2967830224355\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 569.3898901003928\n",
      "Accuracy on evaluation data: 8459 / 10000\n",
      "Epoch 89 training complete\n",
      "Cost on training data: 563.5153263517603\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 564.599612201629\n",
      "Accuracy on evaluation data: 8458 / 10000\n",
      "Epoch 90 training complete\n",
      "Cost on training data: 558.771186654695\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 559.8594682325459\n",
      "Accuracy on evaluation data: 8468 / 10000\n",
      "Epoch 91 training complete\n",
      "Cost on training data: 554.0730308569135\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 555.1629683836679\n",
      "Accuracy on evaluation data: 8467 / 10000\n",
      "Epoch 92 training complete\n",
      "Cost on training data: 549.4071094393272\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 550.4947135376602\n",
      "Accuracy on evaluation data: 8471 / 10000\n",
      "Epoch 93 training complete\n",
      "Cost on training data: 544.800936141523\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 545.8846761253195\n",
      "Accuracy on evaluation data: 8470 / 10000\n",
      "Epoch 94 training complete\n",
      "Cost on training data: 540.2281962896044\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 541.3216627796997\n",
      "Accuracy on evaluation data: 8468 / 10000\n",
      "Epoch 95 training complete\n",
      "Cost on training data: 535.7040277569442\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 536.7864727150557\n",
      "Accuracy on evaluation data: 8478 / 10000\n",
      "Epoch 96 training complete\n",
      "Cost on training data: 531.2216466905932\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 532.3082202045617\n",
      "Accuracy on evaluation data: 8478 / 10000\n",
      "Epoch 97 training complete\n",
      "Cost on training data: 526.7761912282317\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 527.8604076623193\n",
      "Accuracy on evaluation data: 8474 / 10000\n",
      "Epoch 98 training complete\n",
      "Cost on training data: 522.3718849895943\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 523.4513267200759\n",
      "Accuracy on evaluation data: 8479 / 10000\n",
      "Epoch 99 training complete\n",
      "Cost on training data: 518.0097341601407\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 519.0873321805173\n",
      "Accuracy on evaluation data: 8498 / 10000\n",
      "Epoch 100 training complete\n",
      "Cost on training data: 513.6848851980941\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 514.7669423492946\n",
      "Accuracy on evaluation data: 8472 / 10000\n",
      "Epoch 101 training complete\n",
      "Cost on training data: 509.40950077758765\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 510.48381331062535\n",
      "Accuracy on evaluation data: 8495 / 10000\n",
      "Epoch 102 training complete\n",
      "Cost on training data: 505.1728185540946\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 506.2460759665784\n",
      "Accuracy on evaluation data: 8499 / 10000\n",
      "Epoch 103 training complete\n",
      "Cost on training data: 500.97311392339367\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 502.04450849289793\n",
      "Accuracy on evaluation data: 8493 / 10000\n",
      "Epoch 104 training complete\n",
      "Cost on training data: 496.8169916218219\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 497.89231402336185\n",
      "Accuracy on evaluation data: 8492 / 10000\n",
      "Epoch 105 training complete\n",
      "Cost on training data: 492.69226994655276\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 493.7661586130407\n",
      "Accuracy on evaluation data: 8494 / 10000\n",
      "Epoch 106 training complete\n",
      "Cost on training data: 488.6106842249536\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 489.68465674688326\n",
      "Accuracy on evaluation data: 8487 / 10000\n",
      "Epoch 107 training complete\n",
      "Cost on training data: 484.57179455974676\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 485.6361286323456\n",
      "Accuracy on evaluation data: 8502 / 10000\n",
      "Epoch 108 training complete\n",
      "Cost on training data: 480.5690211003278\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 481.63720146948555\n",
      "Accuracy on evaluation data: 8485 / 10000\n",
      "Epoch 109 training complete\n",
      "Cost on training data: 476.60601260927814\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 477.66999785593043\n",
      "Accuracy on evaluation data: 8495 / 10000\n",
      "Epoch 110 training complete\n",
      "Cost on training data: 472.6643001498472\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 473.7384586582347\n",
      "Accuracy on evaluation data: 8485 / 10000\n",
      "Epoch 111 training complete\n",
      "Cost on training data: 468.77128725690244\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 469.82972367105407\n",
      "Accuracy on evaluation data: 8517 / 10000\n",
      "Epoch 112 training complete\n",
      "Cost on training data: 464.9148585516562\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 465.9737848767576\n",
      "Accuracy on evaluation data: 8513 / 10000\n",
      "Epoch 113 training complete\n",
      "Cost on training data: 461.09912916197135\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 462.156792223419\n",
      "Accuracy on evaluation data: 8508 / 10000\n",
      "Epoch 114 training complete\n",
      "Cost on training data: 457.31858003117856\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 458.37748115798524\n",
      "Accuracy on evaluation data: 8498 / 10000\n",
      "Epoch 115 training complete\n",
      "Cost on training data: 453.56354360104126\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 454.6196739157364\n",
      "Accuracy on evaluation data: 8518 / 10000\n",
      "Epoch 116 training complete\n",
      "Cost on training data: 449.8516348166179\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 450.9130092862601\n",
      "Accuracy on evaluation data: 8504 / 10000\n",
      "Epoch 117 training complete\n",
      "Cost on training data: 446.18271051320386\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 447.2381977400216\n",
      "Accuracy on evaluation data: 8505 / 10000\n",
      "Epoch 118 training complete\n",
      "Cost on training data: 442.5362472906832\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 443.5883780188972\n",
      "Accuracy on evaluation data: 8521 / 10000\n",
      "Epoch 119 training complete\n",
      "Cost on training data: 438.93026264108994\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 439.98564514318775\n",
      "Accuracy on evaluation data: 8519 / 10000\n",
      "Epoch 120 training complete\n",
      "Cost on training data: 435.35189592553377\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 436.40304939844066\n",
      "Accuracy on evaluation data: 8525 / 10000\n",
      "Epoch 121 training complete\n",
      "Cost on training data: 431.81464738833614\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 432.8558846715745\n",
      "Accuracy on evaluation data: 8537 / 10000\n",
      "Epoch 122 training complete\n",
      "Cost on training data: 428.31561354508926\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 429.3592397418014\n",
      "Accuracy on evaluation data: 8533 / 10000\n",
      "Epoch 123 training complete\n",
      "Cost on training data: 424.83954255014095\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 425.88722654392814\n",
      "Accuracy on evaluation data: 8525 / 10000\n",
      "Epoch 124 training complete\n",
      "Cost on training data: 421.40449219445276\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 422.44938476917116\n",
      "Accuracy on evaluation data: 8529 / 10000\n",
      "Epoch 125 training complete\n",
      "Cost on training data: 417.99405447114646\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 419.03804618069546\n",
      "Accuracy on evaluation data: 8530 / 10000\n",
      "Epoch 126 training complete\n",
      "Cost on training data: 414.62485883421317\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 415.66062318895564\n",
      "Accuracy on evaluation data: 8533 / 10000\n",
      "Epoch 127 training complete\n",
      "Cost on training data: 411.270881375083\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 412.3174256482399\n",
      "Accuracy on evaluation data: 8527 / 10000\n",
      "Epoch 128 training complete\n",
      "Cost on training data: 407.97420471273716\n",
      "Accuracy on training data: 1000 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on evaluation data: 409.00931605389883\n",
      "Accuracy on evaluation data: 8528 / 10000\n",
      "Epoch 129 training complete\n",
      "Cost on training data: 404.692130326917\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 405.7250855956483\n",
      "Accuracy on evaluation data: 8546 / 10000\n",
      "Epoch 130 training complete\n",
      "Cost on training data: 401.4460579362178\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 402.4796115175271\n",
      "Accuracy on evaluation data: 8540 / 10000\n",
      "Epoch 131 training complete\n",
      "Cost on training data: 398.22770672999377\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 399.2635064054009\n",
      "Accuracy on evaluation data: 8541 / 10000\n",
      "Epoch 132 training complete\n",
      "Cost on training data: 395.0371527373436\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 396.07772690660096\n",
      "Accuracy on evaluation data: 8526 / 10000\n",
      "Epoch 133 training complete\n",
      "Cost on training data: 391.8845876437086\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 392.916773736227\n",
      "Accuracy on evaluation data: 8545 / 10000\n",
      "Epoch 134 training complete\n",
      "Cost on training data: 388.75767767995694\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 389.78995409204964\n",
      "Accuracy on evaluation data: 8543 / 10000\n",
      "Epoch 135 training complete\n",
      "Cost on training data: 385.66194397023986\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 386.6958328325392\n",
      "Accuracy on evaluation data: 8539 / 10000\n",
      "Epoch 136 training complete\n",
      "Cost on training data: 382.595323386143\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 383.6217846496809\n",
      "Accuracy on evaluation data: 8552 / 10000\n",
      "Epoch 137 training complete\n",
      "Cost on training data: 379.55857821733724\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 380.5820781505093\n",
      "Accuracy on evaluation data: 8551 / 10000\n",
      "Epoch 138 training complete\n",
      "Cost on training data: 376.5532799945552\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 377.57343424673587\n",
      "Accuracy on evaluation data: 8551 / 10000\n",
      "Epoch 139 training complete\n",
      "Cost on training data: 373.57603462932985\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 374.6020027344111\n",
      "Accuracy on evaluation data: 8549 / 10000\n",
      "Epoch 140 training complete\n",
      "Cost on training data: 370.62934432884254\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 371.6500595986094\n",
      "Accuracy on evaluation data: 8556 / 10000\n",
      "Epoch 141 training complete\n",
      "Cost on training data: 367.71591498893287\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 368.7322263268049\n",
      "Accuracy on evaluation data: 8556 / 10000\n",
      "Epoch 142 training complete\n",
      "Cost on training data: 364.8174668909675\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 365.8362723615906\n",
      "Accuracy on evaluation data: 8550 / 10000\n",
      "Epoch 143 training complete\n",
      "Cost on training data: 361.95433230624025\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 362.96890998191725\n",
      "Accuracy on evaluation data: 8573 / 10000\n",
      "Epoch 144 training complete\n",
      "Cost on training data: 359.1193705947836\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 360.1385462026065\n",
      "Accuracy on evaluation data: 8562 / 10000\n",
      "Epoch 145 training complete\n",
      "Cost on training data: 356.30678798383144\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 357.317306027809\n",
      "Accuracy on evaluation data: 8565 / 10000\n",
      "Epoch 146 training complete\n",
      "Cost on training data: 353.52173099426466\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 354.5440875316961\n",
      "Accuracy on evaluation data: 8560 / 10000\n",
      "Epoch 147 training complete\n",
      "Cost on training data: 350.7684077318192\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 351.77603577099205\n",
      "Accuracy on evaluation data: 8576 / 10000\n",
      "Epoch 148 training complete\n",
      "Cost on training data: 348.0380670873337\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 349.05298377097967\n",
      "Accuracy on evaluation data: 8568 / 10000\n",
      "Epoch 149 training complete\n",
      "Cost on training data: 345.33865442875447\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 346.34471941994104\n",
      "Accuracy on evaluation data: 8585 / 10000\n",
      "Epoch 150 training complete\n",
      "Cost on training data: 342.667617851979\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 343.6711941647266\n",
      "Accuracy on evaluation data: 8578 / 10000\n",
      "Epoch 151 training complete\n",
      "Cost on training data: 340.01406016580967\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 341.0182656840078\n",
      "Accuracy on evaluation data: 8583 / 10000\n",
      "Epoch 152 training complete\n",
      "Cost on training data: 337.3877899839089\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 338.3934046719833\n",
      "Accuracy on evaluation data: 8573 / 10000\n",
      "Epoch 153 training complete\n",
      "Cost on training data: 334.782728398269\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 335.7869127201685\n",
      "Accuracy on evaluation data: 8593 / 10000\n",
      "Epoch 154 training complete\n",
      "Cost on training data: 332.2125614919033\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 333.2138351685944\n",
      "Accuracy on evaluation data: 8595 / 10000\n",
      "Epoch 155 training complete\n",
      "Cost on training data: 329.66850235468513\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 330.667053001658\n",
      "Accuracy on evaluation data: 8582 / 10000\n",
      "Epoch 156 training complete\n",
      "Cost on training data: 327.1442405711313\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 328.14721156730934\n",
      "Accuracy on evaluation data: 8585 / 10000\n",
      "Epoch 157 training complete\n",
      "Cost on training data: 324.6469647964864\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 325.6467157962401\n",
      "Accuracy on evaluation data: 8594 / 10000\n",
      "Epoch 158 training complete\n",
      "Cost on training data: 322.17811072074585\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 323.1683607470944\n",
      "Accuracy on evaluation data: 8593 / 10000\n",
      "Epoch 159 training complete\n",
      "Cost on training data: 319.72242243718995\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 320.7157712329745\n",
      "Accuracy on evaluation data: 8597 / 10000\n",
      "Epoch 160 training complete\n",
      "Cost on training data: 317.2976369105855\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 318.2938842101495\n",
      "Accuracy on evaluation data: 8595 / 10000\n",
      "Epoch 161 training complete\n",
      "Cost on training data: 314.89689253539507\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 315.88685925599856\n",
      "Accuracy on evaluation data: 8609 / 10000\n",
      "Epoch 162 training complete\n",
      "Cost on training data: 312.5165624863301\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 313.51249150885377\n",
      "Accuracy on evaluation data: 8589 / 10000\n",
      "Epoch 163 training complete\n",
      "Cost on training data: 310.16838517027094\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 311.1576562680981\n",
      "Accuracy on evaluation data: 8606 / 10000\n",
      "Epoch 164 training complete\n",
      "Cost on training data: 307.8336804422918\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 308.8265829565489\n",
      "Accuracy on evaluation data: 8594 / 10000\n",
      "Epoch 165 training complete\n",
      "Cost on training data: 305.5288938322807\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 306.50940715610125\n",
      "Accuracy on evaluation data: 8621 / 10000\n",
      "Epoch 166 training complete\n",
      "Cost on training data: 303.24346228104883\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 304.2242218864362\n",
      "Accuracy on evaluation data: 8609 / 10000\n",
      "Epoch 167 training complete\n",
      "Cost on training data: 300.97776927950093\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 301.96157900891626\n",
      "Accuracy on evaluation data: 8607 / 10000\n",
      "Epoch 168 training complete\n",
      "Cost on training data: 298.7322339362581\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 299.7151328854843\n",
      "Accuracy on evaluation data: 8613 / 10000\n",
      "Epoch 169 training complete\n",
      "Cost on training data: 296.50942406625023\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 297.48848513211885\n",
      "Accuracy on evaluation data: 8607 / 10000\n",
      "Epoch 170 training complete\n",
      "Cost on training data: 294.29933459256387\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 295.2854973866968\n",
      "Accuracy on evaluation data: 8605 / 10000\n",
      "Epoch 171 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 292.13012549581725\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 293.1099816135884\n",
      "Accuracy on evaluation data: 8609 / 10000\n",
      "Epoch 172 training complete\n",
      "Cost on training data: 289.9777968095188\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 290.9595008049781\n",
      "Accuracy on evaluation data: 8600 / 10000\n",
      "Epoch 173 training complete\n",
      "Cost on training data: 287.8365883579789\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 288.81849045534403\n",
      "Accuracy on evaluation data: 8600 / 10000\n",
      "Epoch 174 training complete\n",
      "Cost on training data: 285.7238220095031\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 286.69981462476255\n",
      "Accuracy on evaluation data: 8621 / 10000\n",
      "Epoch 175 training complete\n",
      "Cost on training data: 283.6258745385572\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 284.6043409906328\n",
      "Accuracy on evaluation data: 8615 / 10000\n",
      "Epoch 176 training complete\n",
      "Cost on training data: 281.5572904027504\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 282.5350714674784\n",
      "Accuracy on evaluation data: 8622 / 10000\n",
      "Epoch 177 training complete\n",
      "Cost on training data: 279.5049656096269\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 280.48096805895034\n",
      "Accuracy on evaluation data: 8617 / 10000\n",
      "Epoch 178 training complete\n",
      "Cost on training data: 277.4745385130398\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 278.4353858894336\n",
      "Accuracy on evaluation data: 8629 / 10000\n",
      "Epoch 179 training complete\n",
      "Cost on training data: 275.4626797425981\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 276.4304208933489\n",
      "Accuracy on evaluation data: 8620 / 10000\n",
      "Epoch 180 training complete\n",
      "Cost on training data: 273.4718610970317\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 274.4342526473609\n",
      "Accuracy on evaluation data: 8620 / 10000\n",
      "Epoch 181 training complete\n",
      "Cost on training data: 271.4957536444615\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 272.46195223153984\n",
      "Accuracy on evaluation data: 8624 / 10000\n",
      "Epoch 182 training complete\n",
      "Cost on training data: 269.542875153582\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 270.51077878495806\n",
      "Accuracy on evaluation data: 8615 / 10000\n",
      "Epoch 183 training complete\n",
      "Cost on training data: 267.606025787354\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 268.5711090991321\n",
      "Accuracy on evaluation data: 8632 / 10000\n",
      "Epoch 184 training complete\n",
      "Cost on training data: 265.6912879385234\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 266.65515081274197\n",
      "Accuracy on evaluation data: 8627 / 10000\n",
      "Epoch 185 training complete\n",
      "Cost on training data: 263.7963402029006\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 264.75429320156206\n",
      "Accuracy on evaluation data: 8615 / 10000\n",
      "Epoch 186 training complete\n",
      "Cost on training data: 261.9149213050913\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 262.87611214095307\n",
      "Accuracy on evaluation data: 8634 / 10000\n",
      "Epoch 187 training complete\n",
      "Cost on training data: 260.05642827520666\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 261.01732356986815\n",
      "Accuracy on evaluation data: 8636 / 10000\n",
      "Epoch 188 training complete\n",
      "Cost on training data: 258.2070780244214\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 259.16782697934036\n",
      "Accuracy on evaluation data: 8627 / 10000\n",
      "Epoch 189 training complete\n",
      "Cost on training data: 256.38825962146706\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 257.3405352384896\n",
      "Accuracy on evaluation data: 8639 / 10000\n",
      "Epoch 190 training complete\n",
      "Cost on training data: 254.57503305641526\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 255.53840229559955\n",
      "Accuracy on evaluation data: 8618 / 10000\n",
      "Epoch 191 training complete\n",
      "Cost on training data: 252.78721603451862\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 253.74671562231381\n",
      "Accuracy on evaluation data: 8640 / 10000\n",
      "Epoch 192 training complete\n",
      "Cost on training data: 251.01687027994046\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 251.96936265785388\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "Epoch 193 training complete\n",
      "Cost on training data: 249.26139029729302\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 250.2141293462061\n",
      "Accuracy on evaluation data: 8641 / 10000\n",
      "Epoch 194 training complete\n",
      "Cost on training data: 247.5193666050926\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 248.47565466115543\n",
      "Accuracy on evaluation data: 8643 / 10000\n",
      "Epoch 195 training complete\n",
      "Cost on training data: 245.80698838164227\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 246.76171446700752\n",
      "Accuracy on evaluation data: 8633 / 10000\n",
      "Epoch 196 training complete\n",
      "Cost on training data: 244.10405680354862\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 245.0543700504693\n",
      "Accuracy on evaluation data: 8623 / 10000\n",
      "Epoch 197 training complete\n",
      "Cost on training data: 242.4127952689479\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 243.3606530604844\n",
      "Accuracy on evaluation data: 8645 / 10000\n",
      "Epoch 198 training complete\n",
      "Cost on training data: 240.74409754615877\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 241.6901813676078\n",
      "Accuracy on evaluation data: 8652 / 10000\n",
      "Epoch 199 training complete\n",
      "Cost on training data: 239.09285803911095\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 240.03546497037752\n",
      "Accuracy on evaluation data: 8655 / 10000\n",
      "Epoch 200 training complete\n",
      "Cost on training data: 237.45511006876376\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 238.4011649990543\n",
      "Accuracy on evaluation data: 8640 / 10000\n",
      "Epoch 201 training complete\n",
      "Cost on training data: 235.8395487318408\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 236.7792101566896\n",
      "Accuracy on evaluation data: 8643 / 10000\n",
      "Epoch 202 training complete\n",
      "Cost on training data: 234.2272716636925\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 235.1713515800958\n",
      "Accuracy on evaluation data: 8649 / 10000\n",
      "Epoch 203 training complete\n",
      "Cost on training data: 232.64009392775316\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 233.57768858117876\n",
      "Accuracy on evaluation data: 8657 / 10000\n",
      "Epoch 204 training complete\n",
      "Cost on training data: 231.06025648803256\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 232.00422744436338\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "Epoch 205 training complete\n",
      "Cost on training data: 229.50113737645816\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 230.446376361074\n",
      "Accuracy on evaluation data: 8648 / 10000\n",
      "Epoch 206 training complete\n",
      "Cost on training data: 227.9613288701435\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 228.90688115234724\n",
      "Accuracy on evaluation data: 8635 / 10000\n",
      "Epoch 207 training complete\n",
      "Cost on training data: 226.4381758110974\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 227.37865238024511\n",
      "Accuracy on evaluation data: 8659 / 10000\n",
      "Epoch 208 training complete\n",
      "Cost on training data: 224.9284560826548\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 225.86142546260393\n",
      "Accuracy on evaluation data: 8652 / 10000\n",
      "Epoch 209 training complete\n",
      "Cost on training data: 223.42571925152936\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 224.36448517929603\n",
      "Accuracy on evaluation data: 8651 / 10000\n",
      "Epoch 210 training complete\n",
      "Cost on training data: 221.93911129388366\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 222.87883294846966\n",
      "Accuracy on evaluation data: 8644 / 10000\n",
      "Epoch 211 training complete\n",
      "Cost on training data: 220.47190139394988\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 221.40629755668698\n",
      "Accuracy on evaluation data: 8670 / 10000\n",
      "Epoch 212 training complete\n",
      "Cost on training data: 219.01030895794892\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 219.94575062422624\n",
      "Accuracy on evaluation data: 8669 / 10000\n",
      "Epoch 213 training complete\n",
      "Cost on training data: 217.5751977818785\n",
      "Accuracy on training data: 1000 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on evaluation data: 218.50398161722615\n",
      "Accuracy on evaluation data: 8663 / 10000\n",
      "Epoch 214 training complete\n",
      "Cost on training data: 216.1410921634239\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 217.07424687712538\n",
      "Accuracy on evaluation data: 8668 / 10000\n",
      "Epoch 215 training complete\n",
      "Cost on training data: 214.72808851062655\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 215.6628779753735\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "Epoch 216 training complete\n",
      "Cost on training data: 213.32868182131804\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 214.26660437608732\n",
      "Accuracy on evaluation data: 8655 / 10000\n",
      "Epoch 217 training complete\n",
      "Cost on training data: 211.93864987171057\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 212.8684738578541\n",
      "Accuracy on evaluation data: 8670 / 10000\n",
      "Epoch 218 training complete\n",
      "Cost on training data: 210.56745346032574\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 211.4957952361603\n",
      "Accuracy on evaluation data: 8669 / 10000\n",
      "Epoch 219 training complete\n",
      "Cost on training data: 209.2018362220768\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 210.13578052056153\n",
      "Accuracy on evaluation data: 8658 / 10000\n",
      "Epoch 220 training complete\n",
      "Cost on training data: 207.8545297169114\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 208.7871655883345\n",
      "Accuracy on evaluation data: 8663 / 10000\n",
      "Epoch 221 training complete\n",
      "Cost on training data: 206.52555806424365\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 207.44321184184687\n",
      "Accuracy on evaluation data: 8675 / 10000\n",
      "Epoch 222 training complete\n",
      "Cost on training data: 205.20288567581792\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 206.1259482815936\n",
      "Accuracy on evaluation data: 8671 / 10000\n",
      "Epoch 223 training complete\n",
      "Cost on training data: 203.90099298426017\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 204.82955505382236\n",
      "Accuracy on evaluation data: 8663 / 10000\n",
      "Epoch 224 training complete\n",
      "Cost on training data: 202.60215151330527\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 203.5271082224557\n",
      "Accuracy on evaluation data: 8675 / 10000\n",
      "Epoch 225 training complete\n",
      "Cost on training data: 201.32729211950104\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 202.2492885430603\n",
      "Accuracy on evaluation data: 8671 / 10000\n",
      "Epoch 226 training complete\n",
      "Cost on training data: 200.05826573041242\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 200.98608331729466\n",
      "Accuracy on evaluation data: 8662 / 10000\n",
      "Epoch 227 training complete\n",
      "Cost on training data: 198.80452030257393\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 199.72385297205693\n",
      "Accuracy on evaluation data: 8681 / 10000\n",
      "Epoch 228 training complete\n",
      "Cost on training data: 197.56249514243763\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 198.48401021784198\n",
      "Accuracy on evaluation data: 8674 / 10000\n",
      "Epoch 229 training complete\n",
      "Cost on training data: 196.33397681111282\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 197.25272503104333\n",
      "Accuracy on evaluation data: 8681 / 10000\n",
      "Epoch 230 training complete\n",
      "Cost on training data: 195.11688741296874\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 196.03675583138696\n",
      "Accuracy on evaluation data: 8670 / 10000\n",
      "Epoch 231 training complete\n",
      "Cost on training data: 193.90843858420035\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 194.82837467884244\n",
      "Accuracy on evaluation data: 8673 / 10000\n",
      "Epoch 232 training complete\n",
      "Cost on training data: 192.71589538473293\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 193.63132529726528\n",
      "Accuracy on evaluation data: 8680 / 10000\n",
      "Epoch 233 training complete\n",
      "Cost on training data: 191.5283322524552\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 192.44635993924564\n",
      "Accuracy on evaluation data: 8676 / 10000\n",
      "Epoch 234 training complete\n",
      "Cost on training data: 190.3554642387525\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 191.2713369667143\n",
      "Accuracy on evaluation data: 8684 / 10000\n",
      "Epoch 235 training complete\n",
      "Cost on training data: 189.19321055502974\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 190.10932737185595\n",
      "Accuracy on evaluation data: 8676 / 10000\n",
      "Epoch 236 training complete\n",
      "Cost on training data: 188.04653515096976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 188.95955357892447\n",
      "Accuracy on evaluation data: 8681 / 10000\n",
      "Epoch 237 training complete\n",
      "Cost on training data: 186.90768606576847\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 187.8164456032247\n",
      "Accuracy on evaluation data: 8690 / 10000\n",
      "Epoch 238 training complete\n",
      "Cost on training data: 185.78267608416976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 186.69083478575197\n",
      "Accuracy on evaluation data: 8691 / 10000\n",
      "Epoch 239 training complete\n",
      "Cost on training data: 184.66089341617504\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 185.5761439076098\n",
      "Accuracy on evaluation data: 8674 / 10000\n",
      "Epoch 240 training complete\n",
      "Cost on training data: 183.5644063600065\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 184.47041479513115\n",
      "Accuracy on evaluation data: 8684 / 10000\n",
      "Epoch 241 training complete\n",
      "Cost on training data: 182.46767893247406\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 183.37180177938828\n",
      "Accuracy on evaluation data: 8701 / 10000\n",
      "Epoch 242 training complete\n",
      "Cost on training data: 181.3751288873463\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 182.29416486938817\n",
      "Accuracy on evaluation data: 8659 / 10000\n",
      "Epoch 243 training complete\n",
      "Cost on training data: 180.3023614998412\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 181.21192036552156\n",
      "Accuracy on evaluation data: 8683 / 10000\n",
      "Epoch 244 training complete\n",
      "Cost on training data: 179.23882487556205\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 180.1493439064714\n",
      "Accuracy on evaluation data: 8678 / 10000\n",
      "Epoch 245 training complete\n",
      "Cost on training data: 178.1886654693073\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 179.09575347121464\n",
      "Accuracy on evaluation data: 8695 / 10000\n",
      "Epoch 246 training complete\n",
      "Cost on training data: 177.155832456543\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 178.05698457956237\n",
      "Accuracy on evaluation data: 8692 / 10000\n",
      "Epoch 247 training complete\n",
      "Cost on training data: 176.12028284071093\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 177.02840933672363\n",
      "Accuracy on evaluation data: 8677 / 10000\n",
      "Epoch 248 training complete\n",
      "Cost on training data: 175.0982472218498\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 176.008959026734\n",
      "Accuracy on evaluation data: 8690 / 10000\n",
      "Epoch 249 training complete\n",
      "Cost on training data: 174.07982230108456\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 174.9982003668779\n",
      "Accuracy on evaluation data: 8677 / 10000\n",
      "Epoch 250 training complete\n",
      "Cost on training data: 173.08269759472773\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 173.99550476939288\n",
      "Accuracy on evaluation data: 8665 / 10000\n",
      "Epoch 251 training complete\n",
      "Cost on training data: 172.09183666954894\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 172.99823795388173\n",
      "Accuracy on evaluation data: 8689 / 10000\n",
      "Epoch 252 training complete\n",
      "Cost on training data: 171.10973330497993\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 172.01253393979087\n",
      "Accuracy on evaluation data: 8687 / 10000\n",
      "Epoch 253 training complete\n",
      "Cost on training data: 170.13322425776255\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 171.03686693993885\n",
      "Accuracy on evaluation data: 8703 / 10000\n",
      "Epoch 254 training complete\n",
      "Cost on training data: 169.176867174934\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 170.0693278119458\n",
      "Accuracy on evaluation data: 8707 / 10000\n",
      "Epoch 255 training complete\n",
      "Cost on training data: 168.21550584819127\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 169.11929825706363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on evaluation data: 8686 / 10000\n",
      "Epoch 256 training complete\n",
      "Cost on training data: 167.27076021383306\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 168.17300756353103\n",
      "Accuracy on evaluation data: 8692 / 10000\n",
      "Epoch 257 training complete\n",
      "Cost on training data: 166.3429650604159\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 167.24003183247828\n",
      "Accuracy on evaluation data: 8698 / 10000\n",
      "Epoch 258 training complete\n",
      "Cost on training data: 165.40970962457828\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 166.31134715863317\n",
      "Accuracy on evaluation data: 8693 / 10000\n",
      "Epoch 259 training complete\n",
      "Cost on training data: 164.4936375572631\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 165.39131070994273\n",
      "Accuracy on evaluation data: 8714 / 10000\n",
      "Epoch 260 training complete\n",
      "Cost on training data: 163.5896376836461\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 164.48146048902004\n",
      "Accuracy on evaluation data: 8699 / 10000\n",
      "Epoch 261 training complete\n",
      "Cost on training data: 162.68948874012736\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 163.58468418934345\n",
      "Accuracy on evaluation data: 8708 / 10000\n",
      "Epoch 262 training complete\n",
      "Cost on training data: 161.80553664516322\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 162.70045350957827\n",
      "Accuracy on evaluation data: 8696 / 10000\n",
      "Epoch 263 training complete\n",
      "Cost on training data: 160.92153294624822\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 161.8153756018666\n",
      "Accuracy on evaluation data: 8693 / 10000\n",
      "Epoch 264 training complete\n",
      "Cost on training data: 160.05179778259088\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 160.94880568639132\n",
      "Accuracy on evaluation data: 8701 / 10000\n",
      "Epoch 265 training complete\n",
      "Cost on training data: 159.17877520409942\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 160.08174879840115\n",
      "Accuracy on evaluation data: 8679 / 10000\n",
      "Epoch 266 training complete\n",
      "Cost on training data: 158.32941315028785\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 159.21382571837736\n",
      "Accuracy on evaluation data: 8717 / 10000\n",
      "Epoch 267 training complete\n",
      "Cost on training data: 157.47930650568316\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 158.36720225785075\n",
      "Accuracy on evaluation data: 8717 / 10000\n",
      "Epoch 268 training complete\n",
      "Cost on training data: 156.64342445899052\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 157.53626030455266\n",
      "Accuracy on evaluation data: 8710 / 10000\n",
      "Epoch 269 training complete\n",
      "Cost on training data: 155.81786846438666\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 156.70289614016912\n",
      "Accuracy on evaluation data: 8706 / 10000\n",
      "Epoch 270 training complete\n",
      "Cost on training data: 154.99320879435888\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 155.8810066513742\n",
      "Accuracy on evaluation data: 8703 / 10000\n",
      "Epoch 271 training complete\n",
      "Cost on training data: 154.1816188388909\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 155.06841614131793\n",
      "Accuracy on evaluation data: 8708 / 10000\n",
      "Epoch 272 training complete\n",
      "Cost on training data: 153.38089108608096\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 154.27689330510358\n",
      "Accuracy on evaluation data: 8698 / 10000\n",
      "Epoch 273 training complete\n",
      "Cost on training data: 152.58370932699526\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 153.47666837709372\n",
      "Accuracy on evaluation data: 8705 / 10000\n",
      "Epoch 274 training complete\n",
      "Cost on training data: 151.7938824811606\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 152.67277289639\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 275 training complete\n",
      "Cost on training data: 151.00967420957096\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 151.89490116797438\n",
      "Accuracy on evaluation data: 8711 / 10000\n",
      "Epoch 276 training complete\n",
      "Cost on training data: 150.23053390830637\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 151.11970120289914\n",
      "Accuracy on evaluation data: 8717 / 10000\n",
      "Epoch 277 training complete\n",
      "Cost on training data: 149.4621576329498\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 150.35418445153144\n",
      "Accuracy on evaluation data: 8708 / 10000\n",
      "Epoch 278 training complete\n",
      "Cost on training data: 148.7069036918251\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 149.59262808134417\n",
      "Accuracy on evaluation data: 8708 / 10000\n",
      "Epoch 279 training complete\n",
      "Cost on training data: 147.9609202925422\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 148.84523004549567\n",
      "Accuracy on evaluation data: 8714 / 10000\n",
      "Epoch 280 training complete\n",
      "Cost on training data: 147.21479576874427\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 148.09856722276686\n",
      "Accuracy on evaluation data: 8712 / 10000\n",
      "Epoch 281 training complete\n",
      "Cost on training data: 146.4826456851291\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 147.36942184298834\n",
      "Accuracy on evaluation data: 8713 / 10000\n",
      "Epoch 282 training complete\n",
      "Cost on training data: 145.75392238740238\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 146.64026403522888\n",
      "Accuracy on evaluation data: 8712 / 10000\n",
      "Epoch 283 training complete\n",
      "Cost on training data: 145.02646962086996\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 145.91219398261148\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 284 training complete\n",
      "Cost on training data: 144.32314357641692\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 145.20014308019051\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 285 training complete\n",
      "Cost on training data: 143.61390583409548\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 144.4914655211655\n",
      "Accuracy on evaluation data: 8721 / 10000\n",
      "Epoch 286 training complete\n",
      "Cost on training data: 142.91036562720475\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 143.79285223116818\n",
      "Accuracy on evaluation data: 8719 / 10000\n",
      "Epoch 287 training complete\n",
      "Cost on training data: 142.20893563422894\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 143.095439238677\n",
      "Accuracy on evaluation data: 8704 / 10000\n",
      "Epoch 288 training complete\n",
      "Cost on training data: 141.52620697068917\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 142.4094146130383\n",
      "Accuracy on evaluation data: 8713 / 10000\n",
      "Epoch 289 training complete\n",
      "Cost on training data: 140.85293616729365\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 141.72694388285754\n",
      "Accuracy on evaluation data: 8724 / 10000\n",
      "Epoch 290 training complete\n",
      "Cost on training data: 140.16705569065388\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 141.0504961462709\n",
      "Accuracy on evaluation data: 8706 / 10000\n",
      "Epoch 291 training complete\n",
      "Cost on training data: 139.50521668006886\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 140.3772894287811\n",
      "Accuracy on evaluation data: 8732 / 10000\n",
      "Epoch 292 training complete\n",
      "Cost on training data: 138.84454359057557\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 139.72273513096846\n",
      "Accuracy on evaluation data: 8718 / 10000\n",
      "Epoch 293 training complete\n",
      "Cost on training data: 138.1952289036893\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 139.0664661289358\n",
      "Accuracy on evaluation data: 8720 / 10000\n",
      "Epoch 294 training complete\n",
      "Cost on training data: 137.54472194028844\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 138.42272970506528\n",
      "Accuracy on evaluation data: 8718 / 10000\n",
      "Epoch 295 training complete\n",
      "Cost on training data: 136.9035707795252\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 137.78146290787137\n",
      "Accuracy on evaluation data: 8709 / 10000\n",
      "Epoch 296 training complete\n",
      "Cost on training data: 136.26872162574952\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 137.15104856726498\n",
      "Accuracy on evaluation data: 8704 / 10000\n",
      "Epoch 297 training complete\n",
      "Cost on training data: 135.64225735589835\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 136.51204778931316\n",
      "Accuracy on evaluation data: 8714 / 10000\n",
      "Epoch 298 training complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on training data: 135.0158924237609\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 135.89464642205294\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 299 training complete\n",
      "Cost on training data: 134.40195386170137\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 135.27617098908414\n",
      "Accuracy on evaluation data: 8712 / 10000\n",
      "Epoch 300 training complete\n",
      "Cost on training data: 133.79037921175606\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 134.66805667191161\n",
      "Accuracy on evaluation data: 8707 / 10000\n",
      "Epoch 301 training complete\n",
      "Cost on training data: 133.1946261331882\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 134.06533991775925\n",
      "Accuracy on evaluation data: 8719 / 10000\n",
      "Epoch 302 training complete\n",
      "Cost on training data: 132.58664434094655\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 133.46221432394822\n",
      "Accuracy on evaluation data: 8721 / 10000\n",
      "Epoch 303 training complete\n",
      "Cost on training data: 131.9981176573988\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 132.86146512553935\n",
      "Accuracy on evaluation data: 8726 / 10000\n",
      "Epoch 304 training complete\n",
      "Cost on training data: 131.4041178774625\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 132.28422718983595\n",
      "Accuracy on evaluation data: 8709 / 10000\n",
      "Epoch 305 training complete\n",
      "Cost on training data: 130.82874867135868\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 131.7021574367532\n",
      "Accuracy on evaluation data: 8709 / 10000\n",
      "Epoch 306 training complete\n",
      "Cost on training data: 130.25154659287787\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 131.12601175850287\n",
      "Accuracy on evaluation data: 8723 / 10000\n",
      "Epoch 307 training complete\n",
      "Cost on training data: 129.6798689785597\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 130.55027252821475\n",
      "Accuracy on evaluation data: 8720 / 10000\n",
      "Epoch 308 training complete\n",
      "Cost on training data: 129.1172090964746\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 129.9818992694041\n",
      "Accuracy on evaluation data: 8729 / 10000\n",
      "Epoch 309 training complete\n",
      "Cost on training data: 128.5564348687169\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 129.420725896394\n",
      "Accuracy on evaluation data: 8708 / 10000\n",
      "Epoch 310 training complete\n",
      "Cost on training data: 128.0099944841207\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 128.87162341011884\n",
      "Accuracy on evaluation data: 8726 / 10000\n",
      "Epoch 311 training complete\n",
      "Cost on training data: 127.4589736095258\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 128.33310696957915\n",
      "Accuracy on evaluation data: 8711 / 10000\n",
      "Epoch 312 training complete\n",
      "Cost on training data: 126.91583090728378\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 127.78362261224464\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 313 training complete\n",
      "Cost on training data: 126.3777505996023\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 127.23847147074771\n",
      "Accuracy on evaluation data: 8729 / 10000\n",
      "Epoch 314 training complete\n",
      "Cost on training data: 125.85040207597737\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 126.7154654907875\n",
      "Accuracy on evaluation data: 8726 / 10000\n",
      "Epoch 315 training complete\n",
      "Cost on training data: 125.3214694743136\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 126.1860523833897\n",
      "Accuracy on evaluation data: 8718 / 10000\n",
      "Epoch 316 training complete\n",
      "Cost on training data: 124.80054353429918\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 125.66161946965441\n",
      "Accuracy on evaluation data: 8731 / 10000\n",
      "Epoch 317 training complete\n",
      "Cost on training data: 124.28218933978043\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 125.15436286432131\n",
      "Accuracy on evaluation data: 8718 / 10000\n",
      "Epoch 318 training complete\n",
      "Cost on training data: 123.76927502507596\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 124.63773360236033\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 319 training complete\n",
      "Cost on training data: 123.27177078911647\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 124.13229754538277\n",
      "Accuracy on evaluation data: 8734 / 10000\n",
      "Epoch 320 training complete\n",
      "Cost on training data: 122.76383219891098\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 123.62638370347723\n",
      "Accuracy on evaluation data: 8731 / 10000\n",
      "Epoch 321 training complete\n",
      "Cost on training data: 122.26400710799324\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 123.12471534627139\n",
      "Accuracy on evaluation data: 8742 / 10000\n",
      "Epoch 322 training complete\n",
      "Cost on training data: 121.77314761317432\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 122.63572039453932\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 323 training complete\n",
      "Cost on training data: 121.2842533793021\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 122.15004433055805\n",
      "Accuracy on evaluation data: 8731 / 10000\n",
      "Epoch 324 training complete\n",
      "Cost on training data: 120.80584289573594\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 121.66741165634244\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 325 training complete\n",
      "Cost on training data: 120.31966983567366\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 121.19228590243156\n",
      "Accuracy on evaluation data: 8705 / 10000\n",
      "Epoch 326 training complete\n",
      "Cost on training data: 119.85265738322892\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 120.71552658167302\n",
      "Accuracy on evaluation data: 8723 / 10000\n",
      "Epoch 327 training complete\n",
      "Cost on training data: 119.3865593102256\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 120.24556037878071\n",
      "Accuracy on evaluation data: 8724 / 10000\n",
      "Epoch 328 training complete\n",
      "Cost on training data: 118.9209306144839\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 119.78593735618875\n",
      "Accuracy on evaluation data: 8716 / 10000\n",
      "Epoch 329 training complete\n",
      "Cost on training data: 118.46187840590518\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 119.330946803051\n",
      "Accuracy on evaluation data: 8719 / 10000\n",
      "Epoch 330 training complete\n",
      "Cost on training data: 118.00890241676164\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 118.87372493781464\n",
      "Accuracy on evaluation data: 8730 / 10000\n",
      "Epoch 331 training complete\n",
      "Cost on training data: 117.56023964177969\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 118.42363140997941\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 332 training complete\n",
      "Cost on training data: 117.11368196737999\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 117.97435993088757\n",
      "Accuracy on evaluation data: 8730 / 10000\n",
      "Epoch 333 training complete\n",
      "Cost on training data: 116.67319536360992\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 117.53448469705081\n",
      "Accuracy on evaluation data: 8715 / 10000\n",
      "Epoch 334 training complete\n",
      "Cost on training data: 116.23684343290749\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 117.09221793539893\n",
      "Accuracy on evaluation data: 8726 / 10000\n",
      "Epoch 335 training complete\n",
      "Cost on training data: 115.79512151122492\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 116.65416382533249\n",
      "Accuracy on evaluation data: 8739 / 10000\n",
      "Epoch 336 training complete\n",
      "Cost on training data: 115.36313679833592\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 116.2270629356544\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 337 training complete\n",
      "Cost on training data: 114.94286588191379\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 115.80079663087832\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 338 training complete\n",
      "Cost on training data: 114.52553540874976\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 115.38058351600348\n",
      "Accuracy on evaluation data: 8724 / 10000\n",
      "Epoch 339 training complete\n",
      "Cost on training data: 114.1096463083354\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 114.95936998215225\n",
      "Accuracy on evaluation data: 8742 / 10000\n",
      "Epoch 340 training complete\n",
      "Cost on training data: 113.69510333025339\n",
      "Accuracy on training data: 1000 / 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost on evaluation data: 114.55203611907255\n",
      "Accuracy on evaluation data: 8723 / 10000\n",
      "Epoch 341 training complete\n",
      "Cost on training data: 113.2846116980373\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 114.15126738654051\n",
      "Accuracy on evaluation data: 8728 / 10000\n",
      "Epoch 342 training complete\n",
      "Cost on training data: 112.87502733081325\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 113.73448277783358\n",
      "Accuracy on evaluation data: 8740 / 10000\n",
      "Epoch 343 training complete\n",
      "Cost on training data: 112.47837932827079\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 113.33720477531033\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 344 training complete\n",
      "Cost on training data: 112.08593140354894\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 112.94231692677282\n",
      "Accuracy on evaluation data: 8731 / 10000\n",
      "Epoch 345 training complete\n",
      "Cost on training data: 111.69774834482887\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 112.5473835281657\n",
      "Accuracy on evaluation data: 8733 / 10000\n",
      "Epoch 346 training complete\n",
      "Cost on training data: 111.30516910728544\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 112.15975346057579\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 347 training complete\n",
      "Cost on training data: 110.91584274173339\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 111.77291207107044\n",
      "Accuracy on evaluation data: 8736 / 10000\n",
      "Epoch 348 training complete\n",
      "Cost on training data: 110.5278509967946\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 111.39836223972362\n",
      "Accuracy on evaluation data: 8722 / 10000\n",
      "Epoch 349 training complete\n",
      "Cost on training data: 110.14176898963666\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 110.99665196527394\n",
      "Accuracy on evaluation data: 8744 / 10000\n",
      "Epoch 350 training complete\n",
      "Cost on training data: 109.77424198220999\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 110.62999378816869\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 351 training complete\n",
      "Cost on training data: 109.39517622773822\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 110.25381502827135\n",
      "Accuracy on evaluation data: 8730 / 10000\n",
      "Epoch 352 training complete\n",
      "Cost on training data: 109.03247727429061\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 109.88301523420898\n",
      "Accuracy on evaluation data: 8739 / 10000\n",
      "Epoch 353 training complete\n",
      "Cost on training data: 108.66922321287646\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 109.52938081312705\n",
      "Accuracy on evaluation data: 8731 / 10000\n",
      "Epoch 354 training complete\n",
      "Cost on training data: 108.30653781457995\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 109.1586040723536\n",
      "Accuracy on evaluation data: 8741 / 10000\n",
      "Epoch 355 training complete\n",
      "Cost on training data: 107.9467052025757\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 108.80959728074053\n",
      "Accuracy on evaluation data: 8725 / 10000\n",
      "Epoch 356 training complete\n",
      "Cost on training data: 107.59275425381819\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 108.44603462978161\n",
      "Accuracy on evaluation data: 8737 / 10000\n",
      "Epoch 357 training complete\n",
      "Cost on training data: 107.24686942034127\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 108.10052003079441\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 358 training complete\n",
      "Cost on training data: 106.88921639124396\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 107.753072146595\n",
      "Accuracy on evaluation data: 8727 / 10000\n",
      "Epoch 359 training complete\n",
      "Cost on training data: 106.5488657918482\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 107.4057099507677\n",
      "Accuracy on evaluation data: 8727 / 10000\n",
      "Epoch 360 training complete\n",
      "Cost on training data: 106.21060619289155\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 107.05967545801671\n",
      "Accuracy on evaluation data: 8745 / 10000\n",
      "Epoch 361 training complete\n",
      "Cost on training data: 105.8674042796524\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 106.72461181202661\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 362 training complete\n",
      "Cost on training data: 105.52834414103195\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 106.37973195849116\n",
      "Accuracy on evaluation data: 8747 / 10000\n",
      "Epoch 363 training complete\n",
      "Cost on training data: 105.20001643673582\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 106.0543174690757\n",
      "Accuracy on evaluation data: 8736 / 10000\n",
      "Epoch 364 training complete\n",
      "Cost on training data: 104.86638025927137\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 105.72221954297576\n",
      "Accuracy on evaluation data: 8738 / 10000\n",
      "Epoch 365 training complete\n",
      "Cost on training data: 104.53992822947835\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 105.3916429336809\n",
      "Accuracy on evaluation data: 8750 / 10000\n",
      "Epoch 366 training complete\n",
      "Cost on training data: 104.21806761594031\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 105.0742936862347\n",
      "Accuracy on evaluation data: 8736 / 10000\n",
      "Epoch 367 training complete\n",
      "Cost on training data: 103.90221912275294\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 104.74969818611429\n",
      "Accuracy on evaluation data: 8757 / 10000\n",
      "Epoch 368 training complete\n",
      "Cost on training data: 103.58288398174554\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 104.43858610946937\n",
      "Accuracy on evaluation data: 8734 / 10000\n",
      "Epoch 369 training complete\n",
      "Cost on training data: 103.26757718551909\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 104.10976489162222\n",
      "Accuracy on evaluation data: 8767 / 10000\n",
      "Epoch 370 training complete\n",
      "Cost on training data: 102.9478827247609\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 103.80405217866169\n",
      "Accuracy on evaluation data: 8733 / 10000\n",
      "Epoch 371 training complete\n",
      "Cost on training data: 102.64545350878628\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 103.49670941403157\n",
      "Accuracy on evaluation data: 8739 / 10000\n",
      "Epoch 372 training complete\n",
      "Cost on training data: 102.33316195094297\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 103.17517384426185\n",
      "Accuracy on evaluation data: 8761 / 10000\n",
      "Epoch 373 training complete\n",
      "Cost on training data: 102.03806443684476\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 102.89087565209087\n",
      "Accuracy on evaluation data: 8735 / 10000\n",
      "Epoch 374 training complete\n",
      "Cost on training data: 101.74193438200417\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 102.58927245890692\n",
      "Accuracy on evaluation data: 8749 / 10000\n",
      "Epoch 375 training complete\n",
      "Cost on training data: 101.44593639478545\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 102.28414697140158\n",
      "Accuracy on evaluation data: 8765 / 10000\n",
      "Epoch 376 training complete\n",
      "Cost on training data: 101.145781005092\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 101.99760349740383\n",
      "Accuracy on evaluation data: 8747 / 10000\n",
      "Epoch 377 training complete\n",
      "Cost on training data: 100.85185711008423\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 101.70034622582608\n",
      "Accuracy on evaluation data: 8755 / 10000\n",
      "Epoch 378 training complete\n",
      "Cost on training data: 100.56231005985332\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 101.40730787237328\n",
      "Accuracy on evaluation data: 8748 / 10000\n",
      "Epoch 379 training complete\n",
      "Cost on training data: 100.27786070175576\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 101.11750621797701\n",
      "Accuracy on evaluation data: 8756 / 10000\n",
      "Epoch 380 training complete\n",
      "Cost on training data: 99.99343239437017\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 100.8361093671634\n",
      "Accuracy on evaluation data: 8755 / 10000\n",
      "Epoch 381 training complete\n",
      "Cost on training data: 99.71130109881022\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 100.55825509842352\n",
      "Accuracy on evaluation data: 8742 / 10000\n",
      "Epoch 382 training complete\n",
      "Cost on training data: 99.43097420678745\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 100.27695608639867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on evaluation data: 8759 / 10000\n",
      "Epoch 383 training complete\n",
      "Cost on training data: 99.14987750389443\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 99.99450424394449\n",
      "Accuracy on evaluation data: 8758 / 10000\n",
      "Epoch 384 training complete\n",
      "Cost on training data: 98.87739404118273\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 99.72381137338266\n",
      "Accuracy on evaluation data: 8753 / 10000\n",
      "Epoch 385 training complete\n",
      "Cost on training data: 98.60522497848808\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 99.45065729577462\n",
      "Accuracy on evaluation data: 8763 / 10000\n",
      "Epoch 386 training complete\n",
      "Cost on training data: 98.33665529419115\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 99.18465922248765\n",
      "Accuracy on evaluation data: 8752 / 10000\n",
      "Epoch 387 training complete\n",
      "Cost on training data: 98.07389834642359\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 98.91276865141059\n",
      "Accuracy on evaluation data: 8760 / 10000\n",
      "Epoch 388 training complete\n",
      "Cost on training data: 97.80864022369728\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 98.65132242145674\n",
      "Accuracy on evaluation data: 8765 / 10000\n",
      "Epoch 389 training complete\n",
      "Cost on training data: 97.54958262012629\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 98.39431579281157\n",
      "Accuracy on evaluation data: 8752 / 10000\n",
      "Epoch 390 training complete\n",
      "Cost on training data: 97.28653348640195\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 98.12936807658558\n",
      "Accuracy on evaluation data: 8761 / 10000\n",
      "Epoch 391 training complete\n",
      "Cost on training data: 97.02708239715143\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 97.87865578270019\n",
      "Accuracy on evaluation data: 8753 / 10000\n",
      "Epoch 392 training complete\n",
      "Cost on training data: 96.77466034559204\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 97.61879044703211\n",
      "Accuracy on evaluation data: 8758 / 10000\n",
      "Epoch 393 training complete\n",
      "Cost on training data: 96.52282241082345\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 97.36671680739268\n",
      "Accuracy on evaluation data: 8752 / 10000\n",
      "Epoch 394 training complete\n",
      "Cost on training data: 96.27532021956432\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 97.1148585394103\n",
      "Accuracy on evaluation data: 8759 / 10000\n",
      "Epoch 395 training complete\n",
      "Cost on training data: 96.03056541107951\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 96.87622034885092\n",
      "Accuracy on evaluation data: 8751 / 10000\n",
      "Epoch 396 training complete\n",
      "Cost on training data: 95.78385529365599\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 96.6301397140468\n",
      "Accuracy on evaluation data: 8755 / 10000\n",
      "Epoch 397 training complete\n",
      "Cost on training data: 95.54209052213905\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 96.38612643214147\n",
      "Accuracy on evaluation data: 8756 / 10000\n",
      "Epoch 398 training complete\n",
      "Cost on training data: 95.29856376003197\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 96.13640335872645\n",
      "Accuracy on evaluation data: 8757 / 10000\n",
      "Epoch 399 training complete\n",
      "Cost on training data: 95.05552426063304\n",
      "Accuracy on training data: 1000 / 1000\n",
      "Cost on evaluation data: 95.90522696283384\n",
      "Accuracy on evaluation data: 8753 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1190.2131408750452,\n",
       "  1179.9817978897381,\n",
       "  1170.3228776087863,\n",
       "  1161.1002332615305,\n",
       "  1152.0053503669774,\n",
       "  1142.9578248275029,\n",
       "  1134.0939970523755,\n",
       "  1125.2261963374467,\n",
       "  1116.3978930364269,\n",
       "  1107.6156480393236,\n",
       "  1098.9858198529062,\n",
       "  1090.2365807240471,\n",
       "  1081.5856522769986,\n",
       "  1072.9681304213641,\n",
       "  1064.3304240112741,\n",
       "  1055.7750109424658,\n",
       "  1047.2240572271655,\n",
       "  1038.7874364462189,\n",
       "  1030.3538674696615,\n",
       "  1021.9237389072792,\n",
       "  1013.5806673367566,\n",
       "  1005.255398595949,\n",
       "  996.97743427526734,\n",
       "  988.74051258845122,\n",
       "  980.57596517804086,\n",
       "  972.4288051193912,\n",
       "  964.35686894314767,\n",
       "  956.32047621547201,\n",
       "  948.34790841588517,\n",
       "  940.39840426649084,\n",
       "  932.50505989591102,\n",
       "  924.65952167960484,\n",
       "  916.92262751719329,\n",
       "  909.21371308079199,\n",
       "  901.59576665433326,\n",
       "  894.02832914525993,\n",
       "  886.52239702683846,\n",
       "  879.05579885292275,\n",
       "  871.6349994831387,\n",
       "  864.29298763125121,\n",
       "  857.01548391180586,\n",
       "  849.76668312254037,\n",
       "  842.58030984993366,\n",
       "  835.44919186744244,\n",
       "  828.34778503056407,\n",
       "  821.3242705855746,\n",
       "  814.34460830908006,\n",
       "  807.43909713789969,\n",
       "  800.59387977160065,\n",
       "  793.81757466654676,\n",
       "  787.05792401762415,\n",
       "  780.37809724842134,\n",
       "  773.75646276981149,\n",
       "  767.17609594839746,\n",
       "  760.63789002251474,\n",
       "  754.16671104408738,\n",
       "  747.74550411428629,\n",
       "  741.38589248058361,\n",
       "  735.07381394716606,\n",
       "  728.82222237273152,\n",
       "  722.62258181652578,\n",
       "  716.4704426695738,\n",
       "  710.36098564469512,\n",
       "  704.32163187214485,\n",
       "  698.33551972381508,\n",
       "  692.38845852191025,\n",
       "  686.50181820135572,\n",
       "  680.67193835870717,\n",
       "  674.90123406795112,\n",
       "  669.1597815137734,\n",
       "  663.49325598886082,\n",
       "  657.86921744351571,\n",
       "  652.27085199025635,\n",
       "  646.73873260396067,\n",
       "  641.25301942911642,\n",
       "  635.81445695250397,\n",
       "  630.41804440890337,\n",
       "  625.0851396090452,\n",
       "  619.78227245814583,\n",
       "  614.53273897595614,\n",
       "  609.33477455787602,\n",
       "  604.18634515492613,\n",
       "  599.07411993709809,\n",
       "  594.01370656233576,\n",
       "  588.99867732244377,\n",
       "  584.03320641056359,\n",
       "  579.09583074542263,\n",
       "  574.22410094820611,\n",
       "  569.38989010039279,\n",
       "  564.59961220162904,\n",
       "  559.85946823254585,\n",
       "  555.16296838366793,\n",
       "  550.49471353766023,\n",
       "  545.88467612531952,\n",
       "  541.32166277969975,\n",
       "  536.78647271505565,\n",
       "  532.30822020456174,\n",
       "  527.86040766231929,\n",
       "  523.45132672007594,\n",
       "  519.08733218051725,\n",
       "  514.7669423492946,\n",
       "  510.48381331062535,\n",
       "  506.24607596657842,\n",
       "  502.04450849289793,\n",
       "  497.89231402336185,\n",
       "  493.76615861304072,\n",
       "  489.68465674688326,\n",
       "  485.63612863234562,\n",
       "  481.63720146948555,\n",
       "  477.66999785593043,\n",
       "  473.73845865823472,\n",
       "  469.82972367105407,\n",
       "  465.97378487675758,\n",
       "  462.15679222341902,\n",
       "  458.37748115798524,\n",
       "  454.61967391573643,\n",
       "  450.91300928626009,\n",
       "  447.23819774002158,\n",
       "  443.58837801889717,\n",
       "  439.98564514318775,\n",
       "  436.40304939844066,\n",
       "  432.85588467157447,\n",
       "  429.35923974180139,\n",
       "  425.88722654392814,\n",
       "  422.44938476917116,\n",
       "  419.03804618069546,\n",
       "  415.66062318895564,\n",
       "  412.31742564823992,\n",
       "  409.00931605389883,\n",
       "  405.7250855956483,\n",
       "  402.47961151752708,\n",
       "  399.2635064054009,\n",
       "  396.07772690660096,\n",
       "  392.91677373622701,\n",
       "  389.78995409204964,\n",
       "  386.69583283253922,\n",
       "  383.62178464968088,\n",
       "  380.58207815050929,\n",
       "  377.57343424673587,\n",
       "  374.60200273441109,\n",
       "  371.6500595986094,\n",
       "  368.73222632680489,\n",
       "  365.8362723615906,\n",
       "  362.96890998191725,\n",
       "  360.13854620260651,\n",
       "  357.31730602780902,\n",
       "  354.54408753169611,\n",
       "  351.77603577099205,\n",
       "  349.05298377097967,\n",
       "  346.34471941994104,\n",
       "  343.67119416472661,\n",
       "  341.01826568400782,\n",
       "  338.39340467198332,\n",
       "  335.78691272016852,\n",
       "  333.21383516859441,\n",
       "  330.66705300165802,\n",
       "  328.14721156730934,\n",
       "  325.64671579624007,\n",
       "  323.16836074709443,\n",
       "  320.71577123297448,\n",
       "  318.29388421014949,\n",
       "  315.88685925599856,\n",
       "  313.51249150885377,\n",
       "  311.15765626809809,\n",
       "  308.82658295654892,\n",
       "  306.50940715610125,\n",
       "  304.22422188643623,\n",
       "  301.96157900891626,\n",
       "  299.71513288548431,\n",
       "  297.48848513211885,\n",
       "  295.28549738669682,\n",
       "  293.10998161358839,\n",
       "  290.95950080497812,\n",
       "  288.81849045534403,\n",
       "  286.69981462476255,\n",
       "  284.60434099063281,\n",
       "  282.53507146747842,\n",
       "  280.48096805895034,\n",
       "  278.43538588943358,\n",
       "  276.43042089334892,\n",
       "  274.43425264736089,\n",
       "  272.46195223153984,\n",
       "  270.51077878495806,\n",
       "  268.57110909913212,\n",
       "  266.65515081274197,\n",
       "  264.75429320156206,\n",
       "  262.87611214095307,\n",
       "  261.01732356986815,\n",
       "  259.16782697934036,\n",
       "  257.34053523848962,\n",
       "  255.53840229559955,\n",
       "  253.74671562231381,\n",
       "  251.96936265785388,\n",
       "  250.21412934620611,\n",
       "  248.47565466115543,\n",
       "  246.76171446700752,\n",
       "  245.05437005046929,\n",
       "  243.3606530604844,\n",
       "  241.69018136760781,\n",
       "  240.03546497037752,\n",
       "  238.40116499905429,\n",
       "  236.7792101566896,\n",
       "  235.1713515800958,\n",
       "  233.57768858117876,\n",
       "  232.00422744436338,\n",
       "  230.44637636107399,\n",
       "  228.90688115234724,\n",
       "  227.37865238024511,\n",
       "  225.86142546260393,\n",
       "  224.36448517929603,\n",
       "  222.87883294846966,\n",
       "  221.40629755668698,\n",
       "  219.94575062422624,\n",
       "  218.50398161722615,\n",
       "  217.07424687712538,\n",
       "  215.6628779753735,\n",
       "  214.26660437608732,\n",
       "  212.8684738578541,\n",
       "  211.49579523616029,\n",
       "  210.13578052056153,\n",
       "  208.78716558833449,\n",
       "  207.44321184184687,\n",
       "  206.12594828159359,\n",
       "  204.82955505382236,\n",
       "  203.52710822245569,\n",
       "  202.24928854306029,\n",
       "  200.98608331729466,\n",
       "  199.72385297205693,\n",
       "  198.48401021784198,\n",
       "  197.25272503104333,\n",
       "  196.03675583138696,\n",
       "  194.82837467884244,\n",
       "  193.63132529726528,\n",
       "  192.44635993924564,\n",
       "  191.2713369667143,\n",
       "  190.10932737185595,\n",
       "  188.95955357892447,\n",
       "  187.81644560322471,\n",
       "  186.69083478575197,\n",
       "  185.5761439076098,\n",
       "  184.47041479513115,\n",
       "  183.37180177938828,\n",
       "  182.29416486938817,\n",
       "  181.21192036552156,\n",
       "  180.14934390647139,\n",
       "  179.09575347121464,\n",
       "  178.05698457956237,\n",
       "  177.02840933672363,\n",
       "  176.008959026734,\n",
       "  174.99820036687791,\n",
       "  173.99550476939288,\n",
       "  172.99823795388173,\n",
       "  172.01253393979087,\n",
       "  171.03686693993885,\n",
       "  170.06932781194581,\n",
       "  169.11929825706363,\n",
       "  168.17300756353103,\n",
       "  167.24003183247828,\n",
       "  166.31134715863317,\n",
       "  165.39131070994273,\n",
       "  164.48146048902004,\n",
       "  163.58468418934345,\n",
       "  162.70045350957827,\n",
       "  161.81537560186661,\n",
       "  160.94880568639132,\n",
       "  160.08174879840115,\n",
       "  159.21382571837736,\n",
       "  158.36720225785075,\n",
       "  157.53626030455266,\n",
       "  156.70289614016912,\n",
       "  155.88100665137421,\n",
       "  155.06841614131793,\n",
       "  154.27689330510358,\n",
       "  153.47666837709372,\n",
       "  152.67277289639,\n",
       "  151.89490116797438,\n",
       "  151.11970120289914,\n",
       "  150.35418445153144,\n",
       "  149.59262808134417,\n",
       "  148.84523004549567,\n",
       "  148.09856722276686,\n",
       "  147.36942184298834,\n",
       "  146.64026403522888,\n",
       "  145.91219398261148,\n",
       "  145.20014308019051,\n",
       "  144.49146552116551,\n",
       "  143.79285223116818,\n",
       "  143.09543923867699,\n",
       "  142.40941461303831,\n",
       "  141.72694388285754,\n",
       "  141.05049614627089,\n",
       "  140.3772894287811,\n",
       "  139.72273513096846,\n",
       "  139.06646612893579,\n",
       "  138.42272970506528,\n",
       "  137.78146290787137,\n",
       "  137.15104856726498,\n",
       "  136.51204778931316,\n",
       "  135.89464642205294,\n",
       "  135.27617098908414,\n",
       "  134.66805667191161,\n",
       "  134.06533991775925,\n",
       "  133.46221432394822,\n",
       "  132.86146512553935,\n",
       "  132.28422718983595,\n",
       "  131.7021574367532,\n",
       "  131.12601175850287,\n",
       "  130.55027252821475,\n",
       "  129.9818992694041,\n",
       "  129.420725896394,\n",
       "  128.87162341011884,\n",
       "  128.33310696957915,\n",
       "  127.78362261224464,\n",
       "  127.23847147074771,\n",
       "  126.71546549078749,\n",
       "  126.18605238338969,\n",
       "  125.66161946965441,\n",
       "  125.15436286432131,\n",
       "  124.63773360236033,\n",
       "  124.13229754538277,\n",
       "  123.62638370347723,\n",
       "  123.12471534627139,\n",
       "  122.63572039453932,\n",
       "  122.15004433055805,\n",
       "  121.66741165634244,\n",
       "  121.19228590243156,\n",
       "  120.71552658167302,\n",
       "  120.24556037878071,\n",
       "  119.78593735618875,\n",
       "  119.33094680305101,\n",
       "  118.87372493781464,\n",
       "  118.42363140997941,\n",
       "  117.97435993088757,\n",
       "  117.53448469705081,\n",
       "  117.09221793539893,\n",
       "  116.65416382533249,\n",
       "  116.2270629356544,\n",
       "  115.80079663087832,\n",
       "  115.38058351600348,\n",
       "  114.95936998215225,\n",
       "  114.55203611907255,\n",
       "  114.15126738654051,\n",
       "  113.73448277783358,\n",
       "  113.33720477531033,\n",
       "  112.94231692677282,\n",
       "  112.5473835281657,\n",
       "  112.15975346057579,\n",
       "  111.77291207107044,\n",
       "  111.39836223972362,\n",
       "  110.99665196527394,\n",
       "  110.62999378816869,\n",
       "  110.25381502827135,\n",
       "  109.88301523420898,\n",
       "  109.52938081312705,\n",
       "  109.1586040723536,\n",
       "  108.80959728074053,\n",
       "  108.44603462978161,\n",
       "  108.10052003079441,\n",
       "  107.753072146595,\n",
       "  107.4057099507677,\n",
       "  107.05967545801671,\n",
       "  106.72461181202661,\n",
       "  106.37973195849116,\n",
       "  106.0543174690757,\n",
       "  105.72221954297576,\n",
       "  105.3916429336809,\n",
       "  105.0742936862347,\n",
       "  104.74969818611429,\n",
       "  104.43858610946937,\n",
       "  104.10976489162222,\n",
       "  103.80405217866169,\n",
       "  103.49670941403157,\n",
       "  103.17517384426185,\n",
       "  102.89087565209087,\n",
       "  102.58927245890692,\n",
       "  102.28414697140158,\n",
       "  101.99760349740383,\n",
       "  101.70034622582608,\n",
       "  101.40730787237328,\n",
       "  101.11750621797701,\n",
       "  100.8361093671634,\n",
       "  100.55825509842352,\n",
       "  100.27695608639867,\n",
       "  99.99450424394449,\n",
       "  99.723811373382659,\n",
       "  99.450657295774619,\n",
       "  99.184659222487653,\n",
       "  98.912768651410587,\n",
       "  98.65132242145674,\n",
       "  98.394315792811568,\n",
       "  98.129368076585578,\n",
       "  97.878655782700193,\n",
       "  97.618790447032112,\n",
       "  97.366716807392677,\n",
       "  97.114858539410307,\n",
       "  96.876220348850921,\n",
       "  96.630139714046805,\n",
       "  96.386126432141467,\n",
       "  96.136403358726454,\n",
       "  95.905226962833837],\n",
       " [5766,\n",
       "  6648,\n",
       "  7142,\n",
       "  7290,\n",
       "  7548,\n",
       "  7755,\n",
       "  7787,\n",
       "  7927,\n",
       "  7909,\n",
       "  8044,\n",
       "  7965,\n",
       "  8077,\n",
       "  8090,\n",
       "  8091,\n",
       "  8139,\n",
       "  8152,\n",
       "  8135,\n",
       "  8169,\n",
       "  8157,\n",
       "  8201,\n",
       "  8186,\n",
       "  8174,\n",
       "  8184,\n",
       "  8206,\n",
       "  8239,\n",
       "  8241,\n",
       "  8249,\n",
       "  8243,\n",
       "  8248,\n",
       "  8250,\n",
       "  8259,\n",
       "  8267,\n",
       "  8242,\n",
       "  8278,\n",
       "  8275,\n",
       "  8284,\n",
       "  8278,\n",
       "  8273,\n",
       "  8286,\n",
       "  8297,\n",
       "  8307,\n",
       "  8325,\n",
       "  8315,\n",
       "  8300,\n",
       "  8313,\n",
       "  8307,\n",
       "  8329,\n",
       "  8343,\n",
       "  8338,\n",
       "  8322,\n",
       "  8363,\n",
       "  8364,\n",
       "  8335,\n",
       "  8349,\n",
       "  8370,\n",
       "  8375,\n",
       "  8382,\n",
       "  8383,\n",
       "  8379,\n",
       "  8384,\n",
       "  8373,\n",
       "  8381,\n",
       "  8401,\n",
       "  8398,\n",
       "  8404,\n",
       "  8391,\n",
       "  8388,\n",
       "  8403,\n",
       "  8383,\n",
       "  8398,\n",
       "  8413,\n",
       "  8395,\n",
       "  8427,\n",
       "  8423,\n",
       "  8420,\n",
       "  8428,\n",
       "  8435,\n",
       "  8428,\n",
       "  8442,\n",
       "  8431,\n",
       "  8438,\n",
       "  8443,\n",
       "  8439,\n",
       "  8442,\n",
       "  8453,\n",
       "  8447,\n",
       "  8457,\n",
       "  8450,\n",
       "  8459,\n",
       "  8458,\n",
       "  8468,\n",
       "  8467,\n",
       "  8471,\n",
       "  8470,\n",
       "  8468,\n",
       "  8478,\n",
       "  8478,\n",
       "  8474,\n",
       "  8479,\n",
       "  8498,\n",
       "  8472,\n",
       "  8495,\n",
       "  8499,\n",
       "  8493,\n",
       "  8492,\n",
       "  8494,\n",
       "  8487,\n",
       "  8502,\n",
       "  8485,\n",
       "  8495,\n",
       "  8485,\n",
       "  8517,\n",
       "  8513,\n",
       "  8508,\n",
       "  8498,\n",
       "  8518,\n",
       "  8504,\n",
       "  8505,\n",
       "  8521,\n",
       "  8519,\n",
       "  8525,\n",
       "  8537,\n",
       "  8533,\n",
       "  8525,\n",
       "  8529,\n",
       "  8530,\n",
       "  8533,\n",
       "  8527,\n",
       "  8528,\n",
       "  8546,\n",
       "  8540,\n",
       "  8541,\n",
       "  8526,\n",
       "  8545,\n",
       "  8543,\n",
       "  8539,\n",
       "  8552,\n",
       "  8551,\n",
       "  8551,\n",
       "  8549,\n",
       "  8556,\n",
       "  8556,\n",
       "  8550,\n",
       "  8573,\n",
       "  8562,\n",
       "  8565,\n",
       "  8560,\n",
       "  8576,\n",
       "  8568,\n",
       "  8585,\n",
       "  8578,\n",
       "  8583,\n",
       "  8573,\n",
       "  8593,\n",
       "  8595,\n",
       "  8582,\n",
       "  8585,\n",
       "  8594,\n",
       "  8593,\n",
       "  8597,\n",
       "  8595,\n",
       "  8609,\n",
       "  8589,\n",
       "  8606,\n",
       "  8594,\n",
       "  8621,\n",
       "  8609,\n",
       "  8607,\n",
       "  8613,\n",
       "  8607,\n",
       "  8605,\n",
       "  8609,\n",
       "  8600,\n",
       "  8600,\n",
       "  8621,\n",
       "  8615,\n",
       "  8622,\n",
       "  8617,\n",
       "  8629,\n",
       "  8620,\n",
       "  8620,\n",
       "  8624,\n",
       "  8615,\n",
       "  8632,\n",
       "  8627,\n",
       "  8615,\n",
       "  8634,\n",
       "  8636,\n",
       "  8627,\n",
       "  8639,\n",
       "  8618,\n",
       "  8640,\n",
       "  8658,\n",
       "  8641,\n",
       "  8643,\n",
       "  8633,\n",
       "  8623,\n",
       "  8645,\n",
       "  8652,\n",
       "  8655,\n",
       "  8640,\n",
       "  8643,\n",
       "  8649,\n",
       "  8657,\n",
       "  8658,\n",
       "  8648,\n",
       "  8635,\n",
       "  8659,\n",
       "  8652,\n",
       "  8651,\n",
       "  8644,\n",
       "  8670,\n",
       "  8669,\n",
       "  8663,\n",
       "  8668,\n",
       "  8658,\n",
       "  8655,\n",
       "  8670,\n",
       "  8669,\n",
       "  8658,\n",
       "  8663,\n",
       "  8675,\n",
       "  8671,\n",
       "  8663,\n",
       "  8675,\n",
       "  8671,\n",
       "  8662,\n",
       "  8681,\n",
       "  8674,\n",
       "  8681,\n",
       "  8670,\n",
       "  8673,\n",
       "  8680,\n",
       "  8676,\n",
       "  8684,\n",
       "  8676,\n",
       "  8681,\n",
       "  8690,\n",
       "  8691,\n",
       "  8674,\n",
       "  8684,\n",
       "  8701,\n",
       "  8659,\n",
       "  8683,\n",
       "  8678,\n",
       "  8695,\n",
       "  8692,\n",
       "  8677,\n",
       "  8690,\n",
       "  8677,\n",
       "  8665,\n",
       "  8689,\n",
       "  8687,\n",
       "  8703,\n",
       "  8707,\n",
       "  8686,\n",
       "  8692,\n",
       "  8698,\n",
       "  8693,\n",
       "  8714,\n",
       "  8699,\n",
       "  8708,\n",
       "  8696,\n",
       "  8693,\n",
       "  8701,\n",
       "  8679,\n",
       "  8717,\n",
       "  8717,\n",
       "  8710,\n",
       "  8706,\n",
       "  8703,\n",
       "  8708,\n",
       "  8698,\n",
       "  8705,\n",
       "  8715,\n",
       "  8711,\n",
       "  8717,\n",
       "  8708,\n",
       "  8708,\n",
       "  8714,\n",
       "  8712,\n",
       "  8713,\n",
       "  8712,\n",
       "  8715,\n",
       "  8715,\n",
       "  8721,\n",
       "  8719,\n",
       "  8704,\n",
       "  8713,\n",
       "  8724,\n",
       "  8706,\n",
       "  8732,\n",
       "  8718,\n",
       "  8720,\n",
       "  8718,\n",
       "  8709,\n",
       "  8704,\n",
       "  8714,\n",
       "  8715,\n",
       "  8712,\n",
       "  8707,\n",
       "  8719,\n",
       "  8721,\n",
       "  8726,\n",
       "  8709,\n",
       "  8709,\n",
       "  8723,\n",
       "  8720,\n",
       "  8729,\n",
       "  8708,\n",
       "  8726,\n",
       "  8711,\n",
       "  8722,\n",
       "  8729,\n",
       "  8726,\n",
       "  8718,\n",
       "  8731,\n",
       "  8718,\n",
       "  8715,\n",
       "  8734,\n",
       "  8731,\n",
       "  8742,\n",
       "  8722,\n",
       "  8731,\n",
       "  8715,\n",
       "  8705,\n",
       "  8723,\n",
       "  8724,\n",
       "  8716,\n",
       "  8719,\n",
       "  8730,\n",
       "  8722,\n",
       "  8730,\n",
       "  8715,\n",
       "  8726,\n",
       "  8739,\n",
       "  8722,\n",
       "  8722,\n",
       "  8724,\n",
       "  8742,\n",
       "  8723,\n",
       "  8728,\n",
       "  8740,\n",
       "  8735,\n",
       "  8731,\n",
       "  8733,\n",
       "  8735,\n",
       "  8736,\n",
       "  8722,\n",
       "  8744,\n",
       "  8735,\n",
       "  8730,\n",
       "  8739,\n",
       "  8731,\n",
       "  8741,\n",
       "  8725,\n",
       "  8737,\n",
       "  8735,\n",
       "  8727,\n",
       "  8727,\n",
       "  8745,\n",
       "  8735,\n",
       "  8747,\n",
       "  8736,\n",
       "  8738,\n",
       "  8750,\n",
       "  8736,\n",
       "  8757,\n",
       "  8734,\n",
       "  8767,\n",
       "  8733,\n",
       "  8739,\n",
       "  8761,\n",
       "  8735,\n",
       "  8749,\n",
       "  8765,\n",
       "  8747,\n",
       "  8755,\n",
       "  8748,\n",
       "  8756,\n",
       "  8755,\n",
       "  8742,\n",
       "  8759,\n",
       "  8758,\n",
       "  8753,\n",
       "  8763,\n",
       "  8752,\n",
       "  8760,\n",
       "  8765,\n",
       "  8752,\n",
       "  8761,\n",
       "  8753,\n",
       "  8758,\n",
       "  8752,\n",
       "  8759,\n",
       "  8751,\n",
       "  8755,\n",
       "  8756,\n",
       "  8757,\n",
       "  8753],\n",
       " [1189.8963049138863,\n",
       "  1179.4899479972705,\n",
       "  1169.8009054847139,\n",
       "  1160.5152478984442,\n",
       "  1151.3839076680399,\n",
       "  1142.2816102989132,\n",
       "  1133.3873448200952,\n",
       "  1124.4831091782055,\n",
       "  1115.6035201692259,\n",
       "  1106.8270841844212,\n",
       "  1098.1239581612267,\n",
       "  1089.3982257868204,\n",
       "  1080.7173773698046,\n",
       "  1072.0783346264,\n",
       "  1063.4373496708977,\n",
       "  1054.8715281466875,\n",
       "  1046.294394848376,\n",
       "  1037.8646834747481,\n",
       "  1029.3872729473339,\n",
       "  1020.9644884048899,\n",
       "  1012.5912464995713,\n",
       "  1004.2677059041679,\n",
       "  995.99256169728744,\n",
       "  987.75216198659643,\n",
       "  979.5703090864406,\n",
       "  971.42784327671893,\n",
       "  963.33797632522612,\n",
       "  955.30065177762617,\n",
       "  947.32080673858127,\n",
       "  939.35327410928653,\n",
       "  931.45952091624918,\n",
       "  923.6176036904626,\n",
       "  915.87309410254011,\n",
       "  908.14858753395151,\n",
       "  900.53587519719872,\n",
       "  892.95814955235244,\n",
       "  885.43725310322168,\n",
       "  877.97039936363706,\n",
       "  870.55202724547235,\n",
       "  863.21695467557583,\n",
       "  855.9373051117243,\n",
       "  848.6871501919012,\n",
       "  841.49462950447389,\n",
       "  834.34772550153195,\n",
       "  827.25289375078671,\n",
       "  820.23093610577735,\n",
       "  813.25409852159987,\n",
       "  806.34394492421768,\n",
       "  799.4908668259817,\n",
       "  792.71136006302834,\n",
       "  785.95895025674304,\n",
       "  779.27696676205869,\n",
       "  772.63992111604796,\n",
       "  766.06726848260973,\n",
       "  759.54036963862632,\n",
       "  753.06077529197751,\n",
       "  746.64087068304423,\n",
       "  740.28189046917282,\n",
       "  733.962811401811,\n",
       "  727.70591796486713,\n",
       "  721.50389019220586,\n",
       "  715.36177407969558,\n",
       "  709.25050322387108,\n",
       "  703.21545551673455,\n",
       "  697.22777288064822,\n",
       "  691.27701824421763,\n",
       "  685.38868741588362,\n",
       "  679.56298393050315,\n",
       "  673.78970782313559,\n",
       "  668.0536406804747,\n",
       "  662.39024063375518,\n",
       "  656.75550200145301,\n",
       "  651.17186105973383,\n",
       "  645.63063260632896,\n",
       "  640.1438802381349,\n",
       "  634.70776270967394,\n",
       "  629.31398937599783,\n",
       "  623.97592291985711,\n",
       "  618.68046186228025,\n",
       "  613.43629585412566,\n",
       "  608.23274341853664,\n",
       "  603.08228215166889,\n",
       "  597.97530356865434,\n",
       "  592.91761656148435,\n",
       "  587.89787327535475,\n",
       "  582.92995496134381,\n",
       "  578.00272263297097,\n",
       "  573.12695175319254,\n",
       "  568.29678302243553,\n",
       "  563.51532635176034,\n",
       "  558.77118665469504,\n",
       "  554.07303085691353,\n",
       "  549.4071094393272,\n",
       "  544.80093614152304,\n",
       "  540.2281962896044,\n",
       "  535.70402775694424,\n",
       "  531.22164669059316,\n",
       "  526.77619122823171,\n",
       "  522.37188498959426,\n",
       "  518.00973416014074,\n",
       "  513.68488519809409,\n",
       "  509.40950077758765,\n",
       "  505.17281855409459,\n",
       "  500.97311392339367,\n",
       "  496.8169916218219,\n",
       "  492.69226994655276,\n",
       "  488.61068422495362,\n",
       "  484.57179455974676,\n",
       "  480.5690211003278,\n",
       "  476.60601260927814,\n",
       "  472.66430014984718,\n",
       "  468.77128725690244,\n",
       "  464.91485855165621,\n",
       "  461.09912916197135,\n",
       "  457.31858003117856,\n",
       "  453.56354360104126,\n",
       "  449.85163481661789,\n",
       "  446.18271051320386,\n",
       "  442.53624729068321,\n",
       "  438.93026264108994,\n",
       "  435.35189592553377,\n",
       "  431.81464738833614,\n",
       "  428.31561354508926,\n",
       "  424.83954255014095,\n",
       "  421.40449219445276,\n",
       "  417.99405447114646,\n",
       "  414.62485883421317,\n",
       "  411.27088137508298,\n",
       "  407.97420471273716,\n",
       "  404.69213032691698,\n",
       "  401.44605793621781,\n",
       "  398.22770672999377,\n",
       "  395.0371527373436,\n",
       "  391.88458764370858,\n",
       "  388.75767767995694,\n",
       "  385.66194397023986,\n",
       "  382.59532338614298,\n",
       "  379.55857821733724,\n",
       "  376.55327999455523,\n",
       "  373.57603462932985,\n",
       "  370.62934432884254,\n",
       "  367.71591498893287,\n",
       "  364.81746689096752,\n",
       "  361.95433230624025,\n",
       "  359.11937059478362,\n",
       "  356.30678798383144,\n",
       "  353.52173099426466,\n",
       "  350.7684077318192,\n",
       "  348.03806708733367,\n",
       "  345.33865442875447,\n",
       "  342.667617851979,\n",
       "  340.01406016580967,\n",
       "  337.38778998390887,\n",
       "  334.782728398269,\n",
       "  332.21256149190327,\n",
       "  329.66850235468513,\n",
       "  327.14424057113132,\n",
       "  324.64696479648637,\n",
       "  322.17811072074585,\n",
       "  319.72242243718995,\n",
       "  317.29763691058548,\n",
       "  314.89689253539507,\n",
       "  312.51656248633009,\n",
       "  310.16838517027094,\n",
       "  307.83368044229178,\n",
       "  305.52889383228069,\n",
       "  303.24346228104883,\n",
       "  300.97776927950093,\n",
       "  298.73223393625813,\n",
       "  296.50942406625023,\n",
       "  294.29933459256387,\n",
       "  292.13012549581725,\n",
       "  289.97779680951879,\n",
       "  287.83658835797888,\n",
       "  285.72382200950312,\n",
       "  283.62587453855718,\n",
       "  281.55729040275043,\n",
       "  279.50496560962688,\n",
       "  277.47453851303982,\n",
       "  275.46267974259808,\n",
       "  273.47186109703171,\n",
       "  271.4957536444615,\n",
       "  269.54287515358197,\n",
       "  267.60602578735399,\n",
       "  265.69128793852337,\n",
       "  263.79634020290058,\n",
       "  261.9149213050913,\n",
       "  260.05642827520666,\n",
       "  258.20707802442138,\n",
       "  256.38825962146706,\n",
       "  254.57503305641526,\n",
       "  252.78721603451862,\n",
       "  251.01687027994046,\n",
       "  249.26139029729302,\n",
       "  247.51936660509261,\n",
       "  245.80698838164227,\n",
       "  244.10405680354862,\n",
       "  242.41279526894789,\n",
       "  240.74409754615877,\n",
       "  239.09285803911095,\n",
       "  237.45511006876376,\n",
       "  235.83954873184081,\n",
       "  234.22727166369251,\n",
       "  232.64009392775316,\n",
       "  231.06025648803256,\n",
       "  229.50113737645816,\n",
       "  227.96132887014349,\n",
       "  226.43817581109741,\n",
       "  224.9284560826548,\n",
       "  223.42571925152936,\n",
       "  221.93911129388366,\n",
       "  220.47190139394988,\n",
       "  219.01030895794892,\n",
       "  217.5751977818785,\n",
       "  216.14109216342391,\n",
       "  214.72808851062655,\n",
       "  213.32868182131804,\n",
       "  211.93864987171057,\n",
       "  210.56745346032574,\n",
       "  209.20183622207679,\n",
       "  207.8545297169114,\n",
       "  206.52555806424365,\n",
       "  205.20288567581792,\n",
       "  203.90099298426017,\n",
       "  202.60215151330527,\n",
       "  201.32729211950104,\n",
       "  200.05826573041242,\n",
       "  198.80452030257393,\n",
       "  197.56249514243763,\n",
       "  196.33397681111282,\n",
       "  195.11688741296874,\n",
       "  193.90843858420035,\n",
       "  192.71589538473293,\n",
       "  191.52833225245519,\n",
       "  190.35546423875249,\n",
       "  189.19321055502974,\n",
       "  188.04653515096976,\n",
       "  186.90768606576847,\n",
       "  185.78267608416976,\n",
       "  184.66089341617504,\n",
       "  183.5644063600065,\n",
       "  182.46767893247406,\n",
       "  181.37512888734631,\n",
       "  180.3023614998412,\n",
       "  179.23882487556205,\n",
       "  178.1886654693073,\n",
       "  177.15583245654301,\n",
       "  176.12028284071093,\n",
       "  175.09824722184979,\n",
       "  174.07982230108456,\n",
       "  173.08269759472773,\n",
       "  172.09183666954894,\n",
       "  171.10973330497993,\n",
       "  170.13322425776255,\n",
       "  169.17686717493399,\n",
       "  168.21550584819127,\n",
       "  167.27076021383306,\n",
       "  166.34296506041591,\n",
       "  165.40970962457828,\n",
       "  164.4936375572631,\n",
       "  163.58963768364609,\n",
       "  162.68948874012736,\n",
       "  161.80553664516322,\n",
       "  160.92153294624822,\n",
       "  160.05179778259088,\n",
       "  159.17877520409942,\n",
       "  158.32941315028785,\n",
       "  157.47930650568316,\n",
       "  156.64342445899052,\n",
       "  155.81786846438666,\n",
       "  154.99320879435888,\n",
       "  154.1816188388909,\n",
       "  153.38089108608096,\n",
       "  152.58370932699526,\n",
       "  151.79388248116061,\n",
       "  151.00967420957096,\n",
       "  150.23053390830637,\n",
       "  149.46215763294981,\n",
       "  148.70690369182509,\n",
       "  147.9609202925422,\n",
       "  147.21479576874427,\n",
       "  146.48264568512911,\n",
       "  145.75392238740238,\n",
       "  145.02646962086996,\n",
       "  144.32314357641692,\n",
       "  143.61390583409548,\n",
       "  142.91036562720475,\n",
       "  142.20893563422894,\n",
       "  141.52620697068917,\n",
       "  140.85293616729365,\n",
       "  140.16705569065388,\n",
       "  139.50521668006886,\n",
       "  138.84454359057557,\n",
       "  138.1952289036893,\n",
       "  137.54472194028844,\n",
       "  136.90357077952521,\n",
       "  136.26872162574952,\n",
       "  135.64225735589835,\n",
       "  135.0158924237609,\n",
       "  134.40195386170137,\n",
       "  133.79037921175606,\n",
       "  133.19462613318819,\n",
       "  132.58664434094655,\n",
       "  131.99811765739881,\n",
       "  131.40411787746251,\n",
       "  130.82874867135868,\n",
       "  130.25154659287787,\n",
       "  129.67986897855971,\n",
       "  129.1172090964746,\n",
       "  128.55643486871691,\n",
       "  128.00999448412071,\n",
       "  127.4589736095258,\n",
       "  126.91583090728378,\n",
       "  126.37775059960229,\n",
       "  125.85040207597737,\n",
       "  125.3214694743136,\n",
       "  124.80054353429918,\n",
       "  124.28218933978043,\n",
       "  123.76927502507596,\n",
       "  123.27177078911647,\n",
       "  122.76383219891098,\n",
       "  122.26400710799324,\n",
       "  121.77314761317432,\n",
       "  121.2842533793021,\n",
       "  120.80584289573594,\n",
       "  120.31966983567366,\n",
       "  119.85265738322892,\n",
       "  119.38655931022561,\n",
       "  118.92093061448389,\n",
       "  118.46187840590518,\n",
       "  118.00890241676164,\n",
       "  117.56023964177969,\n",
       "  117.11368196737999,\n",
       "  116.67319536360992,\n",
       "  116.23684343290749,\n",
       "  115.79512151122492,\n",
       "  115.36313679833592,\n",
       "  114.94286588191379,\n",
       "  114.52553540874976,\n",
       "  114.1096463083354,\n",
       "  113.69510333025339,\n",
       "  113.2846116980373,\n",
       "  112.87502733081325,\n",
       "  112.47837932827079,\n",
       "  112.08593140354894,\n",
       "  111.69774834482887,\n",
       "  111.30516910728544,\n",
       "  110.91584274173339,\n",
       "  110.5278509967946,\n",
       "  110.14176898963666,\n",
       "  109.77424198220999,\n",
       "  109.39517622773822,\n",
       "  109.03247727429061,\n",
       "  108.66922321287646,\n",
       "  108.30653781457995,\n",
       "  107.9467052025757,\n",
       "  107.59275425381819,\n",
       "  107.24686942034127,\n",
       "  106.88921639124396,\n",
       "  106.5488657918482,\n",
       "  106.21060619289155,\n",
       "  105.8674042796524,\n",
       "  105.52834414103195,\n",
       "  105.20001643673582,\n",
       "  104.86638025927137,\n",
       "  104.53992822947835,\n",
       "  104.21806761594031,\n",
       "  103.90221912275294,\n",
       "  103.58288398174554,\n",
       "  103.26757718551909,\n",
       "  102.9478827247609,\n",
       "  102.64545350878628,\n",
       "  102.33316195094297,\n",
       "  102.03806443684476,\n",
       "  101.74193438200417,\n",
       "  101.44593639478545,\n",
       "  101.145781005092,\n",
       "  100.85185711008423,\n",
       "  100.56231005985332,\n",
       "  100.27786070175576,\n",
       "  99.993432394370174,\n",
       "  99.711301098810225,\n",
       "  99.430974206787454,\n",
       "  99.14987750389443,\n",
       "  98.877394041182725,\n",
       "  98.605224978488081,\n",
       "  98.336655294191146,\n",
       "  98.07389834642359,\n",
       "  97.808640223697282,\n",
       "  97.549582620126287,\n",
       "  97.28653348640195,\n",
       "  97.027082397151432,\n",
       "  96.774660345592039,\n",
       "  96.522822410823451,\n",
       "  96.275320219564321,\n",
       "  96.030565411079507,\n",
       "  95.783855293655989,\n",
       "  95.542090522139048,\n",
       "  95.298563760031968,\n",
       "  95.055524260633035],\n",
       " [678,\n",
       "  789,\n",
       "  841,\n",
       "  875,\n",
       "  910,\n",
       "  928,\n",
       "  946,\n",
       "  952,\n",
       "  949,\n",
       "  955,\n",
       "  962,\n",
       "  967,\n",
       "  967,\n",
       "  971,\n",
       "  975,\n",
       "  975,\n",
       "  979,\n",
       "  981,\n",
       "  983,\n",
       "  986,\n",
       "  986,\n",
       "  988,\n",
       "  984,\n",
       "  990,\n",
       "  990,\n",
       "  991,\n",
       "  992,\n",
       "  992,\n",
       "  992,\n",
       "  993,\n",
       "  993,\n",
       "  993,\n",
       "  994,\n",
       "  994,\n",
       "  995,\n",
       "  996,\n",
       "  996,\n",
       "  996,\n",
       "  996,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  997,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  999,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  998,\n",
       "  999,\n",
       "  999,\n",
       "  999,\n",
       "  998,\n",
       "  999,\n",
       "  999,\n",
       "  999,\n",
       "  999,\n",
       "  999,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000,\n",
       "  1000])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10], cost = network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data[:1000], 400, 10, 0.5, evaluation_data=test_data, lmbda = 0.1, monitor_evaluation_cost=True, monitor_evaluation_accuracy=True, monitor_training_cost=True, monitor_training_accuracy=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on training data: 45789 / 50000\n",
      "Accuracy on evaluation data: 9156 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on training data: 46773 / 50000\n",
      "Accuracy on evaluation data: 9305 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on training data: 47594 / 50000\n",
      "Accuracy on evaluation data: 9481 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on training data: 47727 / 50000\n",
      "Accuracy on evaluation data: 9486 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on training data: 47969 / 50000\n",
      "Accuracy on evaluation data: 9531 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on training data: 47746 / 50000\n",
      "Accuracy on evaluation data: 9471 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on training data: 48144 / 50000\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on training data: 48199 / 50000\n",
      "Accuracy on evaluation data: 9564 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on training data: 47879 / 50000\n",
      "Accuracy on evaluation data: 9521 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on training data: 48292 / 50000\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on training data: 48201 / 50000\n",
      "Accuracy on evaluation data: 9560 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on training data: 48290 / 50000\n",
      "Accuracy on evaluation data: 9597 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on training data: 48298 / 50000\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on training data: 48261 / 50000\n",
      "Accuracy on evaluation data: 9562 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on training data: 48376 / 50000\n",
      "Accuracy on evaluation data: 9597 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on training data: 47813 / 50000\n",
      "Accuracy on evaluation data: 9504 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on training data: 48339 / 50000\n",
      "Accuracy on evaluation data: 9590 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on training data: 48383 / 50000\n",
      "Accuracy on evaluation data: 9622 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on training data: 48372 / 50000\n",
      "Accuracy on evaluation data: 9628 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on training data: 48229 / 50000\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on training data: 48408 / 50000\n",
      "Accuracy on evaluation data: 9571 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on training data: 48206 / 50000\n",
      "Accuracy on evaluation data: 9555 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on training data: 47761 / 50000\n",
      "Accuracy on evaluation data: 9462 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on training data: 48214 / 50000\n",
      "Accuracy on evaluation data: 9531 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on training data: 48562 / 50000\n",
      "Accuracy on evaluation data: 9609 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on training data: 48420 / 50000\n",
      "Accuracy on evaluation data: 9614 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on training data: 48446 / 50000\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on training data: 48520 / 50000\n",
      "Accuracy on evaluation data: 9616 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on training data: 48467 / 50000\n",
      "Accuracy on evaluation data: 9600 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on training data: 48414 / 50000\n",
      "Accuracy on evaluation data: 9570 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9156,\n",
       "  9305,\n",
       "  9481,\n",
       "  9486,\n",
       "  9531,\n",
       "  9471,\n",
       "  9572,\n",
       "  9564,\n",
       "  9521,\n",
       "  9577,\n",
       "  9560,\n",
       "  9597,\n",
       "  9581,\n",
       "  9562,\n",
       "  9597,\n",
       "  9504,\n",
       "  9590,\n",
       "  9622,\n",
       "  9628,\n",
       "  9577,\n",
       "  9571,\n",
       "  9555,\n",
       "  9462,\n",
       "  9531,\n",
       "  9609,\n",
       "  9614,\n",
       "  9608,\n",
       "  9616,\n",
       "  9600,\n",
       "  9570],\n",
       " [],\n",
       " [45789,\n",
       "  46773,\n",
       "  47594,\n",
       "  47727,\n",
       "  47969,\n",
       "  47746,\n",
       "  48144,\n",
       "  48199,\n",
       "  47879,\n",
       "  48292,\n",
       "  48201,\n",
       "  48290,\n",
       "  48298,\n",
       "  48261,\n",
       "  48376,\n",
       "  47813,\n",
       "  48339,\n",
       "  48383,\n",
       "  48372,\n",
       "  48229,\n",
       "  48408,\n",
       "  48206,\n",
       "  47761,\n",
       "  48214,\n",
       "  48562,\n",
       "  48420,\n",
       "  48446,\n",
       "  48520,\n",
       "  48467,\n",
       "  48414])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5, evaluation_data=test_data, lmbda = 5.0, monitor_evaluation_accuracy=True, monitor_training_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9421 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9597 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9636 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9707 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9711 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9732 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9737 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9734 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9733 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9715 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9754 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9730 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9713 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9737 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9759 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9763 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9760 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9756 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9744 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9769 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9711 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9758 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9762 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9727 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9759 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9768 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9751 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9754 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9421,\n",
       "  9572,\n",
       "  9597,\n",
       "  9650,\n",
       "  9636,\n",
       "  9707,\n",
       "  9711,\n",
       "  9732,\n",
       "  9737,\n",
       "  9734,\n",
       "  9733,\n",
       "  9715,\n",
       "  9754,\n",
       "  9730,\n",
       "  9713,\n",
       "  9737,\n",
       "  9759,\n",
       "  9763,\n",
       "  9760,\n",
       "  9756,\n",
       "  9744,\n",
       "  9769,\n",
       "  9711,\n",
       "  9758,\n",
       "  9762,\n",
       "  9727,\n",
       "  9759,\n",
       "  9768,\n",
       "  9751,\n",
       "  9754],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 100, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.5, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 8739 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9047 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9161 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9237 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9303 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9379 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9402 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9421 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9458 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9483 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9511 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9534 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9536 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9557 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9557 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9560 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9579 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9580 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9588 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9591 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9607 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9604 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9605 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9597 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9614 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9628 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9612 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9623 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [8739,\n",
       "  9047,\n",
       "  9161,\n",
       "  9237,\n",
       "  9303,\n",
       "  9379,\n",
       "  9402,\n",
       "  9421,\n",
       "  9458,\n",
       "  9468,\n",
       "  9483,\n",
       "  9511,\n",
       "  9534,\n",
       "  9536,\n",
       "  9557,\n",
       "  9557,\n",
       "  9560,\n",
       "  9579,\n",
       "  9580,\n",
       "  9588,\n",
       "  9591,\n",
       "  9607,\n",
       "  9604,\n",
       "  9605,\n",
       "  9597,\n",
       "  9614,\n",
       "  9628,\n",
       "  9608,\n",
       "  9612,\n",
       "  9623],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.large_weight_initializer()\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9265 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9387 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9442 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9487 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9509 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9516 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9521 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9554 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9562 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9568 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9569 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9573 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9584 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9588 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9586 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9589 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9622 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9618 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9619 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9630 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9620 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9610 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9621 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9630 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9640 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9633 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9636 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9265,\n",
       "  9387,\n",
       "  9442,\n",
       "  9487,\n",
       "  9509,\n",
       "  9516,\n",
       "  9521,\n",
       "  9554,\n",
       "  9562,\n",
       "  9568,\n",
       "  9569,\n",
       "  9573,\n",
       "  9584,\n",
       "  9588,\n",
       "  9586,\n",
       "  9608,\n",
       "  9589,\n",
       "  9622,\n",
       "  9618,\n",
       "  9619,\n",
       "  9630,\n",
       "  9620,\n",
       "  9610,\n",
       "  9621,\n",
       "  9629,\n",
       "  9638,\n",
       "  9630,\n",
       "  9640,\n",
       "  9633,\n",
       "  9636],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 10], cost=network2.CrossEntropyCost)\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda = 5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 1009 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 961 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 915 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 1030 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 991 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 983 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 1064 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 990 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 1030 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [915,\n",
       "  991,\n",
       "  1030,\n",
       "  1064,\n",
       "  1009,\n",
       "  1064,\n",
       "  961,\n",
       "  1064,\n",
       "  983,\n",
       "  961,\n",
       "  1064,\n",
       "  1064,\n",
       "  1064,\n",
       "  983,\n",
       "  1064,\n",
       "  961,\n",
       "  983,\n",
       "  1030,\n",
       "  915,\n",
       "  1030,\n",
       "  990,\n",
       "  1030,\n",
       "  990,\n",
       "  1064,\n",
       "  991,\n",
       "  983,\n",
       "  983,\n",
       "  1064,\n",
       "  990,\n",
       "  1030],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 10.0, lmbda = 1000.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\neural-networks-and-deep-learning\\my\\src\\network2.py:348: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\neural-networks-and-deep-learning\\my\\src\\network2.py:223: RuntimeWarning: overflow encountered in multiply\n",
      "  for w, nw in zip(self.weights, nabla_w)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 10])\n",
    "net.SGD(training_data[:1000], 30, 10, 10.0, lmbda = 1000.0, evaluation_data=validation_data[:100], monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 14 / 100\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 22 / 100\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 16 / 100\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 34 / 100\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 30 / 100\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 28 / 100\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 25 / 100\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 20 / 100\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 39 / 100\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 27 / 100\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 26 / 100\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 31 / 100\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 25 / 100\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 35 / 100\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 28 / 100\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 14 / 100\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 48 / 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\neural-networks-and-deep-learning\\my\\src\\network2.py:348: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 32 / 100\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 35 / 100\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 32 / 100\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 16 / 100\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 23 / 100\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 30 / 100\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 23 / 100\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 15 / 100\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 34 / 100\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 28 / 100\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 19 / 100\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 17 / 100\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 26 / 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [14,\n",
       "  22,\n",
       "  16,\n",
       "  34,\n",
       "  30,\n",
       "  28,\n",
       "  25,\n",
       "  20,\n",
       "  39,\n",
       "  27,\n",
       "  26,\n",
       "  31,\n",
       "  25,\n",
       "  35,\n",
       "  28,\n",
       "  14,\n",
       "  48,\n",
       "  32,\n",
       "  35,\n",
       "  32,\n",
       "  16,\n",
       "  23,\n",
       "  30,\n",
       "  23,\n",
       "  15,\n",
       "  34,\n",
       "  28,\n",
       "  19,\n",
       "  17,\n",
       "  26],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 10])\n",
    "net.SGD(training_data[:1000], 30, 10, 10.0, lmbda = 20.0, evaluation_data=validation_data[:100], monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\neural-networks-and-deep-learning\\my\\src\\network2.py:348: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1.0 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 10 / 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10,\n",
       "  10],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 10])\n",
    "net.SGD(training_data[:1000], 30, 10, 100.0, lmbda = 20.0, evaluation_data=validation_data[:100], monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 58 / 100\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 47 / 100\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 54 / 100\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 54 / 100\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 59 / 100\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 59 / 100\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 67 / 100\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 57 / 100\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 64 / 100\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 59 / 100\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 71 / 100\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 52 / 100\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 40 / 100\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 51 / 100\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 63 / 100\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 65 / 100\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 60 / 100\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 47 / 100\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 73 / 100\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 66 / 100\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 62 / 100\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 61 / 100\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 66 / 100\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 59 / 100\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 67 / 100\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 68 / 100\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 61 / 100\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 51 / 100\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 68 / 100\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 65 / 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [58,\n",
       "  47,\n",
       "  54,\n",
       "  54,\n",
       "  59,\n",
       "  59,\n",
       "  67,\n",
       "  57,\n",
       "  64,\n",
       "  59,\n",
       "  71,\n",
       "  52,\n",
       "  40,\n",
       "  51,\n",
       "  63,\n",
       "  65,\n",
       "  60,\n",
       "  47,\n",
       "  73,\n",
       "  66,\n",
       "  62,\n",
       "  61,\n",
       "  66,\n",
       "  59,\n",
       "  67,\n",
       "  68,\n",
       "  61,\n",
       "  51,\n",
       "  68,\n",
       "  65],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 10])\n",
    "net.SGD(training_data[:1000], 30, 10, 1.0, lmbda = 20.0, evaluation_data=validation_data[:100], monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9290 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9398 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9460 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9452 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9485 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9503 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9512 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9533 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9520 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9522 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9533 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9548 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9558 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9568 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9567 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9571 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9593 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9586 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9554 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9604 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9608 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9589 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9593 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9619 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9614 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9617 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9612 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9616 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9611 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9290,\n",
       "  9398,\n",
       "  9460,\n",
       "  9452,\n",
       "  9485,\n",
       "  9503,\n",
       "  9512,\n",
       "  9533,\n",
       "  9520,\n",
       "  9522,\n",
       "  9533,\n",
       "  9548,\n",
       "  9558,\n",
       "  9568,\n",
       "  9567,\n",
       "  9571,\n",
       "  9593,\n",
       "  9586,\n",
       "  9554,\n",
       "  9581,\n",
       "  9604,\n",
       "  9608,\n",
       "  9589,\n",
       "  9593,\n",
       "  9619,\n",
       "  9614,\n",
       "  9617,\n",
       "  9612,\n",
       "  9616,\n",
       "  9611],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chapter 5\n",
    "# The vanishing gradient problem\n",
    "\n",
    "import mnist_loader\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "import network2\n",
    "net = network2.Network([784, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 9209 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9416 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9509 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9534 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9572 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9578 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9591 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9609 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9584 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9612 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9630 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9642 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9640 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9623 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9644 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9637 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9674 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9639 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9651 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9672 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9660 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9658 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9670 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9673 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9652 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9650 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9658 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9677 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [9209,\n",
       "  9416,\n",
       "  9509,\n",
       "  9534,\n",
       "  9572,\n",
       "  9578,\n",
       "  9591,\n",
       "  9609,\n",
       "  9584,\n",
       "  9612,\n",
       "  9630,\n",
       "  9642,\n",
       "  9640,\n",
       "  9623,\n",
       "  9644,\n",
       "  9637,\n",
       "  9674,\n",
       "  9639,\n",
       "  9660,\n",
       "  9651,\n",
       "  9672,\n",
       "  9660,\n",
       "  9658,\n",
       "  9670,\n",
       "  9673,\n",
       "  9663,\n",
       "  9652,\n",
       "  9650,\n",
       "  9658,\n",
       "  9677],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 8465 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 9188 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9426 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9491 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9541 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9552 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9590 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9571 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9611 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9605 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9582 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9623 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9623 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9621 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9646 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9579 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9634 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9619 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9643 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9652 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9663 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9640 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9579 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9657 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9638 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9613 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9613 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9642 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9659 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9654 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [8465,\n",
       "  9188,\n",
       "  9426,\n",
       "  9491,\n",
       "  9541,\n",
       "  9552,\n",
       "  9590,\n",
       "  9571,\n",
       "  9611,\n",
       "  9605,\n",
       "  9582,\n",
       "  9623,\n",
       "  9623,\n",
       "  9621,\n",
       "  9646,\n",
       "  9579,\n",
       "  9634,\n",
       "  9619,\n",
       "  9643,\n",
       "  9652,\n",
       "  9663,\n",
       "  9640,\n",
       "  9579,\n",
       "  9657,\n",
       "  9638,\n",
       "  9613,\n",
       "  9613,\n",
       "  9642,\n",
       "  9659,\n",
       "  9654],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 training complete\n",
      "Accuracy on evaluation data: 3404 / 10000\n",
      "Epoch 1 training complete\n",
      "Accuracy on evaluation data: 8294 / 10000\n",
      "Epoch 2 training complete\n",
      "Accuracy on evaluation data: 9137 / 10000\n",
      "Epoch 3 training complete\n",
      "Accuracy on evaluation data: 9314 / 10000\n",
      "Epoch 4 training complete\n",
      "Accuracy on evaluation data: 9387 / 10000\n",
      "Epoch 5 training complete\n",
      "Accuracy on evaluation data: 9469 / 10000\n",
      "Epoch 6 training complete\n",
      "Accuracy on evaluation data: 9468 / 10000\n",
      "Epoch 7 training complete\n",
      "Accuracy on evaluation data: 9531 / 10000\n",
      "Epoch 8 training complete\n",
      "Accuracy on evaluation data: 9546 / 10000\n",
      "Epoch 9 training complete\n",
      "Accuracy on evaluation data: 9566 / 10000\n",
      "Epoch 10 training complete\n",
      "Accuracy on evaluation data: 9573 / 10000\n",
      "Epoch 11 training complete\n",
      "Accuracy on evaluation data: 9584 / 10000\n",
      "Epoch 12 training complete\n",
      "Accuracy on evaluation data: 9594 / 10000\n",
      "Epoch 13 training complete\n",
      "Accuracy on evaluation data: 9581 / 10000\n",
      "Epoch 14 training complete\n",
      "Accuracy on evaluation data: 9579 / 10000\n",
      "Epoch 15 training complete\n",
      "Accuracy on evaluation data: 9605 / 10000\n",
      "Epoch 16 training complete\n",
      "Accuracy on evaluation data: 9625 / 10000\n",
      "Epoch 17 training complete\n",
      "Accuracy on evaluation data: 9554 / 10000\n",
      "Epoch 18 training complete\n",
      "Accuracy on evaluation data: 9611 / 10000\n",
      "Epoch 19 training complete\n",
      "Accuracy on evaluation data: 9632 / 10000\n",
      "Epoch 20 training complete\n",
      "Accuracy on evaluation data: 9591 / 10000\n",
      "Epoch 21 training complete\n",
      "Accuracy on evaluation data: 9561 / 10000\n",
      "Epoch 22 training complete\n",
      "Accuracy on evaluation data: 9619 / 10000\n",
      "Epoch 23 training complete\n",
      "Accuracy on evaluation data: 9573 / 10000\n",
      "Epoch 24 training complete\n",
      "Accuracy on evaluation data: 9577 / 10000\n",
      "Epoch 25 training complete\n",
      "Accuracy on evaluation data: 9551 / 10000\n",
      "Epoch 26 training complete\n",
      "Accuracy on evaluation data: 9634 / 10000\n",
      "Epoch 27 training complete\n",
      "Accuracy on evaluation data: 9629 / 10000\n",
      "Epoch 28 training complete\n",
      "Accuracy on evaluation data: 9606 / 10000\n",
      "Epoch 29 training complete\n",
      "Accuracy on evaluation data: 9651 / 10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([],\n",
       " [3404,\n",
       "  8294,\n",
       "  9137,\n",
       "  9314,\n",
       "  9387,\n",
       "  9469,\n",
       "  9468,\n",
       "  9531,\n",
       "  9546,\n",
       "  9566,\n",
       "  9573,\n",
       "  9584,\n",
       "  9594,\n",
       "  9581,\n",
       "  9579,\n",
       "  9605,\n",
       "  9625,\n",
       "  9554,\n",
       "  9611,\n",
       "  9632,\n",
       "  9591,\n",
       "  9561,\n",
       "  9619,\n",
       "  9573,\n",
       "  9577,\n",
       "  9551,\n",
       "  9634,\n",
       "  9629,\n",
       "  9606,\n",
       "  9651],\n",
       " [],\n",
       " [])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = network2.Network([784, 30, 30, 30, 30, 10])\n",
    "net.SGD(training_data, 30, 10, 0.1, lmbda=5.0, evaluation_data=validation_data, monitor_evaluation_accuracy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
